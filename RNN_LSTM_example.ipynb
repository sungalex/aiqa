{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CNN-Review\" data-toc-modified-id=\"CNN-Review-1\">CNN Review</a></span></li><li><span><a href=\"#RNN-&amp;-LSTM\" data-toc-modified-id=\"RNN-&amp;-LSTM-2\">RNN &amp; LSTM</a></span></li><li><span><a href=\"#LSTM-주식가격-예측\" data-toc-modified-id=\"LSTM-주식가격-예측-3\">LSTM 주식가격 예측</a></span></li><li><span><a href=\"#Bidrectional\" data-toc-modified-id=\"Bidrectional-4\">Bidrectional</a></span></li><li><span><a href=\"#다음-문자-예측\" data-toc-modified-id=\"다음-문자-예측-5\">다음 문자 예측</a></span></li><li><span><a href=\"#Embedding-(영화-리뷰-데이터)\" data-toc-modified-id=\"Embedding-(영화-리뷰-데이터)-6\">Embedding (영화 리뷰 데이터)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRTZBqVKq_fL"
   },
   "source": [
    "# CNN Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2960,
     "status": "ok",
     "timestamp": 1578876507409,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "zen5H0Q2Widh",
    "outputId": "6fd48214-f09c-4a94-d10a-33e635b67e46"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1578877751441,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "KmtXteQ1X2XQ",
    "outputId": "98aeaa58-3fce-403d-aa89-7b4760585dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 784) (60000, 10)\n",
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# one-hot encoding : categorical data(범주형 데이터) 변환\n",
    "# 데이터의 차원은 데이터의 변수의 수를 의미\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZtHF99jX_hd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alex/venvs/tensorflow-1x/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.layers.Input(shape=(784,))\n",
    "net = tf.keras.layers.Dense(64)(X)\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Dense(10)(net)\n",
    "Y = tf.keras.layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1578879762285,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "JIOqddCvddE3",
    "outputId": "702ced8b-5265-47f5-e982-6f8494ec0ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9855,
     "status": "ok",
     "timestamp": 1578879827706,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "jnTZzeajdmZ2",
    "outputId": "9faca87c-4c19-4488-e430-f68a39212546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 9.7509 - acc: 0.7740\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 1.0699 - acc: 0.8036\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.6917 - acc: 0.8474\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.5455 - acc: 0.8731\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.4568 - acc: 0.8894\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.3957 - acc: 0.8998\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.3486 - acc: 0.9104\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 0.3127 - acc: 0.9166\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.2794 - acc: 0.9236\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.2542 - acc: 0.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10db79eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1578879832904,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "H-7E6xtOdtUe",
    "outputId": "f65bc6a8-1f84-45bf-ce20-b8df61d686e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/sample - loss: 0.4465 - acc: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4464563358489424, 0.9146]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rLZYDdHq7ai"
   },
   "source": [
    "# RNN & LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1578882051695,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "7EcZ_A6qi93E",
    "outputId": "429a62b8-15e0-43b4-a9dc-90a7c97bd002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YL6_hz_7q4e8"
   },
   "outputs": [],
   "source": [
    "# cell = tf.keras.layers.SimpleRNNCell(32)\n",
    "cell = tf.keras.layers.LSTMCell(32)\n",
    "\n",
    "X = tf.keras.layers.Input(shape=(28,28))\n",
    "net = tf.keras.layers.RNN(cell)(X)\n",
    "net = tf.keras.layers.Dense(10)(net)\n",
    "Y = tf.keras.layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1578882139604,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "ST97odHzsjQj",
    "outputId": "e10b3b15-e1c6-4a94-866c-bf038223e344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 32)                7808      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,138\n",
      "Trainable params: 8,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 92677,
     "status": "ok",
     "timestamp": 1578882233618,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "lp6kPXcJssba",
    "outputId": "779fe96f-be72-4310-8609-600c724226e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alex/venvs/tensorflow-1x/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 1.3159 - acc: 0.5782\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4057 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2588 - acc: 0.9258\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1983 - acc: 0.9441\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1643 - acc: 0.9534\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1458 - acc: 0.9585\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1298 - acc: 0.9632\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1172 - acc: 0.9667\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1070 - acc: 0.9693\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0999 - acc: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cae2668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1578882086378,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "u9vK82cmswQi",
    "outputId": "9981cfea-0dcc-4fcc-ddef-34d3e15d686a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.1076 - acc: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1076139676451683, 0.9687]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1578888986578,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "pY8qoBu7EEd6",
    "outputId": "c2060dbd-d7ff-4da8-f7d2-3f2bcb918f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28) (60000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# minmax normalize\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "km92x9mTEoZ_"
   },
   "outputs": [],
   "source": [
    "# cell = tf.keras.layers.SimpleRNNCell(64)\n",
    "cell = tf.keras.layers.LSTMCell(64)\n",
    "\n",
    "X = tf.keras.layers.Input(shape=(28,28))\n",
    "net = tf.keras.layers.RNN(cell)(X)\n",
    "net = tf.keras.layers.Dense(10)(net)\n",
    "Y = tf.keras.layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1578891873164,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "id9niETQFdqP",
    "outputId": "8ac4aa8c-fe80-4c8a-83fb-a24d19983489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  (None, 64)                23808     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 24,458\n",
      "Trainable params: 24,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 158986,
     "status": "ok",
     "timestamp": 1578892033221,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "yRfESER_Fjlf",
    "outputId": "5c76fa6c-6b87-4c65-99a0-e5e71daf4ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 159us/sample - loss: 0.9351 - acc: 0.6996\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 146us/sample - loss: 0.2695 - acc: 0.9202\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.1771 - acc: 0.9474\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.1423 - acc: 0.9579\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.1161 - acc: 0.9662\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.1003 - acc: 0.9708\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: 0.0918 - acc: 0.9729\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.0784 - acc: 0.9769\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0727 - acc: 0.9781\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.0658 - acc: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ba74828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 151us/sample - loss: 0.0968 - acc: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09681864804923535, 0.9704]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ve5EE_3jFvrp",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RNN in module tensorflow.python.keras.layers.recurrent:\n",
      "\n",
      "class RNN(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Base class for recurrent layers.\n",
      " |  \n",
      " |  Arguments:\n",
      " |    cell: A RNN cell instance or a list of RNN cell instances.\n",
      " |      A RNN cell is a class that has:\n",
      " |      - A `call(input_at_t, states_at_t)` method, returning\n",
      " |        `(output_at_t, states_at_t_plus_1)`. The call method of the\n",
      " |        cell can also take the optional argument `constants`, see\n",
      " |        section \"Note on passing external constants\" below.\n",
      " |      - A `state_size` attribute. This can be a single integer\n",
      " |        (single state) in which case it is the size of the recurrent\n",
      " |        state. This can also be a list/tuple of integers (one size per\n",
      " |        state).\n",
      " |        The `state_size` can also be TensorShape or tuple/list of\n",
      " |        TensorShape, to represent high dimension state.\n",
      " |      - A `output_size` attribute. This can be a single integer or a\n",
      " |        TensorShape, which represent the shape of the output. For backward\n",
      " |        compatible reason, if this attribute is not available for the\n",
      " |        cell, the value will be inferred by the first element of the\n",
      " |        `state_size`.\n",
      " |      - A `get_initial_state(inputs=None, batch_size=None, dtype=None)`\n",
      " |        method that creates a tensor meant to be fed to `call()` as the\n",
      " |        initial state, if the user didn't specify any initial state via other\n",
      " |        means. The returned initial state should have a shape of\n",
      " |        [batch_size, cell.state_size]. The cell might choose to create a\n",
      " |        tensor full of zeros, or full of other values based on the cell's\n",
      " |        implementation.\n",
      " |        `inputs` is the input tensor to the RNN layer, which should\n",
      " |        contain the batch size as its shape[0], and also dtype. Note that\n",
      " |        the shape[0] might be `None` during the graph construction. Either\n",
      " |        the `inputs` or the pair of `batch_size` and `dtype` are provided.\n",
      " |        `batch_size` is a scalar tensor that represents the batch size\n",
      " |        of the inputs. `dtype` is `tf.DType` that represents the dtype of\n",
      " |        the inputs.\n",
      " |        For backward compatible reason, if this method is not implemented\n",
      " |        by the cell, the RNN layer will create a zero filled tensor with the\n",
      " |        size of [batch_size, cell.state_size].\n",
      " |      In the case that `cell` is a list of RNN cell instances, the cells\n",
      " |      will be stacked on top of each other in the RNN, resulting in an\n",
      " |      efficient stacked RNN.\n",
      " |    return_sequences: Boolean. Whether to return the last output\n",
      " |      in the output sequence, or the full sequence.\n",
      " |    return_state: Boolean. Whether to return the last state\n",
      " |      in addition to the output.\n",
      " |    go_backwards: Boolean (default False).\n",
      " |      If True, process the input sequence backwards and return the\n",
      " |      reversed sequence.\n",
      " |    stateful: Boolean (default False). If True, the last state\n",
      " |      for each sample at index i in a batch will be used as initial\n",
      " |      state for the sample of index i in the following batch.\n",
      " |    unroll: Boolean (default False).\n",
      " |      If True, the network will be unrolled, else a symbolic loop will be used.\n",
      " |      Unrolling can speed-up a RNN,\n",
      " |      although it tends to be more memory-intensive.\n",
      " |      Unrolling is only suitable for short sequences.\n",
      " |    time_major: The shape format of the `inputs` and `outputs` tensors.\n",
      " |      If True, the inputs and outputs will be in shape\n",
      " |      `(timesteps, batch, ...)`, whereas in the False case, it will be\n",
      " |      `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n",
      " |      efficient because it avoids transposes at the beginning and end of the\n",
      " |      RNN calculation. However, most TensorFlow data is batch-major, so by\n",
      " |      default this function accepts input and emits output in batch-major\n",
      " |      form.\n",
      " |  \n",
      " |  Call arguments:\n",
      " |    inputs: Input tensor.\n",
      " |    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n",
      " |      a given timestep should be masked.\n",
      " |    training: Python boolean indicating whether the layer should behave in\n",
      " |      training mode or in inference mode. This argument is passed to the cell\n",
      " |      when calling it. This is for use with cells that use dropout.\n",
      " |    initial_state: List of initial state tensors to be passed to the first\n",
      " |      call of the cell.\n",
      " |    constants: List of constant tensors to be passed to the cell at each\n",
      " |      timestep.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape `(batch_size, timesteps, ...)` or\n",
      " |    `(timesteps, batch_size, ...)` when time_major is True.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    - If `return_state`: a list of tensors. The first tensor is\n",
      " |      the output. The remaining tensors are the last states,\n",
      " |      each with shape `(batch_size, state_size)`, where `state_size` could\n",
      " |      be a high dimension tensor shape.\n",
      " |    - If `return_sequences`: N-D tensor with shape\n",
      " |      `(batch_size, timesteps, output_size)`, where `output_size` could\n",
      " |      be a high dimension tensor shape, or\n",
      " |      `(timesteps, batch_size, output_size)` when `time_major` is True.\n",
      " |    - Else, N-D tensor with shape `(batch_size, output_size)`, where\n",
      " |      `output_size` could be a high dimension tensor shape.\n",
      " |  \n",
      " |  Masking:\n",
      " |    This layer supports masking for input data with a variable number\n",
      " |    of timesteps. To introduce masks to your data,\n",
      " |    use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n",
      " |    set to `True`.\n",
      " |  \n",
      " |  Note on using statefulness in RNNs:\n",
      " |    You can set RNN layers to be 'stateful', which means that the states\n",
      " |    computed for the samples in one batch will be reused as initial states\n",
      " |    for the samples in the next batch. This assumes a one-to-one mapping\n",
      " |    between samples in different successive batches.\n",
      " |  \n",
      " |    To enable statefulness:\n",
      " |      - Specify `stateful=True` in the layer constructor.\n",
      " |      - Specify a fixed batch size for your model, by passing\n",
      " |        If sequential model:\n",
      " |          `batch_input_shape=(...)` to the first layer in your model.\n",
      " |        Else for functional model with 1 or more Input layers:\n",
      " |          `batch_shape=(...)` to all the first layers in your model.\n",
      " |        This is the expected shape of your inputs\n",
      " |        *including the batch size*.\n",
      " |        It should be a tuple of integers, e.g. `(32, 10, 100)`.\n",
      " |      - Specify `shuffle=False` when calling fit().\n",
      " |  \n",
      " |    To reset the states of your model, call `.reset_states()` on either\n",
      " |    a specific layer, or on your entire model.\n",
      " |  \n",
      " |  Note on specifying the initial state of RNNs:\n",
      " |    You can specify the initial state of RNN layers symbolically by\n",
      " |    calling them with the keyword argument `initial_state`. The value of\n",
      " |    `initial_state` should be a tensor or list of tensors representing\n",
      " |    the initial state of the RNN layer.\n",
      " |  \n",
      " |    You can specify the initial state of RNN layers numerically by\n",
      " |    calling `reset_states` with the keyword argument `states`. The value of\n",
      " |    `states` should be a numpy array or list of numpy arrays representing\n",
      " |    the initial state of the RNN layer.\n",
      " |  \n",
      " |  Note on passing external constants to RNNs:\n",
      " |    You can pass \"external\" constants to the cell using the `constants`\n",
      " |    keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n",
      " |    requires that the `cell.call` method accepts the same keyword argument\n",
      " |    `constants`. Such constants can be used to condition the cell\n",
      " |    transformation on additional static inputs (not changing over time),\n",
      " |    a.k.a. an attention mechanism.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  ```python\n",
      " |  # First, let's define a RNN Cell, as a layer subclass.\n",
      " |  \n",
      " |  class MinimalRNNCell(keras.layers.Layer):\n",
      " |  \n",
      " |      def __init__(self, units, **kwargs):\n",
      " |          self.units = units\n",
      " |          self.state_size = units\n",
      " |          super(MinimalRNNCell, self).__init__(**kwargs)\n",
      " |  \n",
      " |      def build(self, input_shape):\n",
      " |          self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
      " |                                        initializer='uniform',\n",
      " |                                        name='kernel')\n",
      " |          self.recurrent_kernel = self.add_weight(\n",
      " |              shape=(self.units, self.units),\n",
      " |              initializer='uniform',\n",
      " |              name='recurrent_kernel')\n",
      " |          self.built = True\n",
      " |  \n",
      " |      def call(self, inputs, states):\n",
      " |          prev_output = states[0]\n",
      " |          h = K.dot(inputs, self.kernel)\n",
      " |          output = h + K.dot(prev_output, self.recurrent_kernel)\n",
      " |          return output, [output]\n",
      " |  \n",
      " |  # Let's use this cell in a RNN layer:\n",
      " |  \n",
      " |  cell = MinimalRNNCell(32)\n",
      " |  x = keras.Input((None, 5))\n",
      " |  layer = RNN(cell)\n",
      " |  y = layer(x)\n",
      " |  \n",
      " |  # Here's how to use the cell to build a stacked RNN:\n",
      " |  \n",
      " |  cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n",
      " |  x = keras.Input((None, 5))\n",
      " |  layer = RNN(cells)\n",
      " |  y = layer(x)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RNN\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, inputs, initial_state=None, constants=None, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __init__(self, cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, time_major=False, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs, mask=None, training=None, initial_state=None, constants=None)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_initial_state(self, inputs)\n",
      " |  \n",
      " |  reset_states(self, states=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  states\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: If anything other than None is passed, it signals the updates\n",
      " |          are conditional on some of the layer's inputs,\n",
      " |          and thus they should only be run where these inputs are available.\n",
      " |          This is the case for BatchNormalization updates, for instance.\n",
      " |          If None, the updates will be taken into account unconditionally,\n",
      " |          and you are responsible for making sure that any dependency they might\n",
      " |          have is available at runtime.\n",
      " |          A step counter might fall into this category.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: initializer instance (callable).\n",
      " |        regularizer: regularizer instance (callable).\n",
      " |        trainable: whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n",
      " |          Note, if the current variable scope is marked as non-trainable\n",
      " |          then this parameter is ignored and any added variables are also\n",
      " |          marked as non-trainable. `trainable` defaults to `True` unless\n",
      " |          `synchronization` is set to `ON_READ`.\n",
      " |        constraint: constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable.  Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance.  If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Apply the layer on a input.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.layers.RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PFF4IRLTYa_s"
   },
   "source": [
    "# LSTM 주식가격 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MWO_UO_IU4v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1578894515513,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "ZQp26er7WpFa",
    "outputId": "49d84096-d97f-41b1-d647-2f0c46bbb48e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.314634</td>\n",
       "      <td>0.218994</td>\n",
       "      <td>0.012476</td>\n",
       "      <td>0.216982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.186679</td>\n",
       "      <td>0.209481</td>\n",
       "      <td>0.208782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.210516</td>\n",
       "      <td>0.205289</td>\n",
       "      <td>0.203559</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.187750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>0.193935</td>\n",
       "      <td>0.203642</td>\n",
       "      <td>0.208665</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.196552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0.213751</td>\n",
       "      <td>0.208180</td>\n",
       "      <td>0.191792</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.192092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       # Open      High       Low    Volume     Close\n",
       "727  0.306974  0.314634  0.218994  0.012476  0.216982\n",
       "728  0.186679  0.209481  0.208782  0.000000  0.217448\n",
       "729  0.210516  0.205289  0.203559  0.000260  0.187750\n",
       "730  0.193935  0.203642  0.208665  0.002985  0.196552\n",
       "731  0.213751  0.208180  0.191792  0.000466  0.192092"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"https://raw.githubusercontent.com/blackdew/DeepLearningZeroToAll/master/data-02-stock_daily.csv\", skiprows=1)\n",
    "dataset.head()\n",
    "print(dataset.shape)\n",
    "\n",
    "# minmax norm\n",
    "data_norm = (dataset - dataset.min(axis=0)) / (dataset.max(axis=0) - dataset.min(axis=0))\n",
    "data_norm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1578894518116,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "viaDdSqyKcmZ",
    "outputId": "214b8b74-b119-4e79-e45a-fb8e585841cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.13751054e-01 2.08179810e-01 1.91791832e-01 4.66075110e-04\n",
      "  1.92092403e-01]\n",
      " [1.93935034e-01 2.03641926e-01 2.08664571e-01 2.98467330e-03\n",
      "  1.96551555e-01]\n",
      " [2.10516454e-01 2.05289413e-01 2.03558748e-01 2.59926504e-04\n",
      "  1.87749731e-01]\n",
      " [1.86678765e-01 2.09480567e-01 2.08781843e-01 0.00000000e+00\n",
      "  2.17448151e-01]\n",
      " [3.06973882e-01 3.14634137e-01 2.18993665e-01 1.24764722e-02\n",
      "  2.16981885e-01]]\n",
      "(732, 5)\n"
     ]
    }
   ],
   "source": [
    "data_norm = data_norm.values[::-1]  # array reverse\n",
    "print(data_norm[:5])\n",
    "print(data_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6V2zXnaBT3YK"
   },
   "source": [
    "axis는 shape의 인덱스 순번과 동일함(sum, min, max 등을 연산하면 axis로 지정한 인덱스의 원소가 1개가 됨) <br>\n",
    "shape가 (732, 5) 일때, axis=0은 732개의 행을 1개로 만듦. axis=1은 5개의 열을 1개로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1578894522870,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "RlUZux9PSzkZ",
    "outputId": "eaa94831-aab7-4e31-c49f-f7c63c2c703a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(725, 7, 5)\n",
      "(725,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x_train = []\n",
    "# for i in range(len(data_norm) - 7):\n",
    "#     x_train.append(data_norm[i:i+7])\n",
    "\n",
    "# 과거 7일간의 주가로 그 다음날의 주가를 예측하기 위한 데이터 전처리\n",
    "x_train = np.array([data_norm[i:i+7] for i in range(len(data_norm) - 7)])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = []\n",
    "y_train = np.array([data_norm[i+7, -1] for i in range(len(data_norm) - 7)])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1578894577461,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "gdWxGdXRVsvj",
    "outputId": "3b7694f1-c1d2-473e-d5b4-30a635f68f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 7, 5) (525,)\n",
      "(200, 7, 5) (200,)\n"
     ]
    }
   ],
   "source": [
    "x_test, x_train = x_train[-200:], x_train[:-200]\n",
    "y_test, y_train = y_train[-200:], y_train[:-200]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZE31kVcZQei"
   },
   "outputs": [],
   "source": [
    "cell = tf.keras.layers.LSTMCell(64)\n",
    "\n",
    "X = tf.keras.layers.Input(shape=(7,5))\n",
    "net = tf.keras.layers.RNN(cell)(X)\n",
    "Y = tf.keras.layers.Dense(1)(net)   # 회귀이기 때문에 1개의 값을 결과로 가짐\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'    # 회귀에는 loss 함수로 mse 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1578894819349,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "l46ZLwXJaOTq",
    "outputId": "cebf0e28-a9b9-413d-eddd-a4b56a572dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 7, 5)]            0         \n",
      "_________________________________________________________________\n",
      "rnn_2 (RNN)                  (None, 64)                17920     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,985\n",
      "Trainable params: 17,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9254,
     "status": "ok",
     "timestamp": 1578894846241,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "8CI_gSUGaQZa",
    "outputId": "7c12d2a7-b5a1-4e2e-e287-c67e08ee4dd5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 1s 1ms/sample - loss: 0.0423\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 0s 230us/sample - loss: 0.0059\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 0s 220us/sample - loss: 0.0032\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 0s 233us/sample - loss: 0.0023\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 0s 267us/sample - loss: 0.0022\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 0s 288us/sample - loss: 0.0022\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 0s 271us/sample - loss: 0.0022\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 0s 262us/sample - loss: 0.0022\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 0s 260us/sample - loss: 0.0021\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 0s 292us/sample - loss: 0.0022\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 0s 235us/sample - loss: 0.0022\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 0s 264us/sample - loss: 0.0021\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 0s 229us/sample - loss: 0.0021\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 0s 216us/sample - loss: 0.0022\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 0s 228us/sample - loss: 0.0021\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 0s 229us/sample - loss: 0.0022\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 0s 240us/sample - loss: 0.0021\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 0s 254us/sample - loss: 0.0020\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 0s 255us/sample - loss: 0.0019\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 0s 264us/sample - loss: 0.0019\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 0s 272us/sample - loss: 0.0020\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 0s 237us/sample - loss: 0.0019\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 0s 219us/sample - loss: 0.0018\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 0s 223us/sample - loss: 0.0018\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 0s 220us/sample - loss: 0.0018\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 0s 238us/sample - loss: 0.0018\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 0s 222us/sample - loss: 0.0017\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 0s 210us/sample - loss: 0.0018\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 0s 231us/sample - loss: 0.0017\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 0s 239us/sample - loss: 0.0017\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 0s 253us/sample - loss: 0.0017\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 0s 246us/sample - loss: 0.0017\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 0s 244us/sample - loss: 0.0017\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 0s 249us/sample - loss: 0.0017\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 0s 236us/sample - loss: 0.0016\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 0s 237us/sample - loss: 0.0016\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 0s 228us/sample - loss: 0.0015\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 0s 229us/sample - loss: 0.0015\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 0s 214us/sample - loss: 0.0015\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 0s 238us/sample - loss: 0.0015\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 0s 227us/sample - loss: 0.0017\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 0s 201us/sample - loss: 0.0015\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 0s 224us/sample - loss: 0.0014\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 0s 212us/sample - loss: 0.0014\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 0s 224us/sample - loss: 0.0014\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 0s 201us/sample - loss: 0.0014\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 0s 226us/sample - loss: 0.0014\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 0s 220us/sample - loss: 0.0014\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 0s 218us/sample - loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c3d0048>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1620,
     "status": "ok",
     "timestamp": 1578894853004,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "RCMFgkROaaha",
    "outputId": "ab64a93e-72a2-416f-cd87-916342c62ea5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD3CAYAAADv7LToAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5icVdn/P2fazuzObO81m947IYQQAqELRIqIgAWpr/L6/kRFUXlRQQUb8ooiKCqgRJr0XkIJEEjvZZPtvc/OzE6f8/vjzE42ySbZ3exmdpPzuS6uZJ/nmfPczyz5zj33uYuQUqLRaDSa0Y0h3gZoNBqN5ujRYq7RaDTHAVrMNRqN5jhAi7lGo9EcB2gx12g0muMAUzxumpmZKceMGROPW2s0Gs2oZd26da1Syqy+zsVFzMeMGcPatWvjcWuNRqMZtQghqg51TodZNBqN5jhAi7lGo9EcB2gx12g0muOAuMTM+yIYDFJbW4vP54u3KcOC1WqlsLAQs9kcb1M0Gs1xyIgR89raWhwOB2PGjEEIEW9zhhQpJW1tbdTW1lJaWhpvczQazXHIiAmz+Hw+MjIyjjshBxBCkJGRcdx+69BoNPFnxIg5cFwKeQ/H87NpNJr40y8xF0IYhRA/F0K8fojzZwkhXhFCPCWE+N3QmqjRaDTDQ5cvyNNra4hERn8r8P565hcCL9JHjF0ol/N24FIp5RVAtxDi7D6uu1EIsVYIsbalpeVobB7xrFixgscffzzeZmg0miPw0qZ6vvfMZj7a2xpvU46afom5lPIFKeWnhzg9EdgupfRHf34eOKOPNR6WUs6XUs7PyuqzGvW4IRwOEw6H422GRqM5Ag2dah/rP+vr4mzJ0TMU2SwZQHuvn9ujxwbNT1/axvb6rqMy6kCm5idz50XTDnvNhx9+yC9/+UsWLVpEIBAA4IYbbuC2224jGAxyzjnncP7553PHHXeQmppKd3c3v/3tb3E4HNxzzz1s3bqV7OxsKioqWL58+ZDar9Fohp4GpxLz17c2ctfnQ9gTRkyC34AZCsvbgLReP6dHj406wuEwdrudH//4xwB897vfpbW1lS1btrBhwwbMZjNXXXUVv/rVrygsLOT111/n4Ycf5qqrrmLdunU8/fTTANx8883xfAyNRtNPGru8OBJMuPwhXt/ayOXzCuNt0qAZCjHfA0wXQiREQy3LgfePZsEjedDDyaRJk2J/Hz9+PCtXrmT+/PmxYp+9e/fywAMPACqdsqCggOrqaqZOnRp73bx5846t0RqNZlA0dPpYMjGLjTWdvL29adjF/JYn1jM2M4lbz5l05IsHyEDFPHjgASllWAhxF/AvIYQbaAHeHArj4sG6detif1+7di3f//732b59e+xYcXEx3/72t8nJyYkda2lpYdeuXbGfP/nkE5YsWXJsDNZoNINCSkmD08eZk7PxhxxUtHqgux0S04flfs1dPl7d0sA3lo4flvUHJOZSyvN7/i6EeAj4Xyllk5RyJbByqI2LB2azmVtvvRWPx8PYsWOxWq0YjcbY+bvvvptbbrmF9PR0IpEId9xxB8XFxSxdupSvfvWrpKenH/QajUYz8ujyhvAGw+SmWBECTHvegF9dBKd/H5beDkNcG/LipnoiEj4/p2BI1+1h0GEWKeVNQ2nISOGkk06Kxcx7eOihh2J/nzRpUiw23pubb75Zx8o1mlFEQ5cXgLwUGzaLkVl8gEQg3r8XEHDG7UN6v+c21DGzMIXx2fYhXbeHEVUBGm8MBgMm0+jdzdZoNP2nJ5MlN8XKuFQjZxg20jj+SihcAOVDG2goa3Kxrb6Lz88eHq8cRlCjrZHAkiVLdKxbozlBaIyKeV6KFWvrSpKEn49TzyDPF4S6dUd49cB4cVM9BgEXzcof0nV7oz1zjUZzQtLg9GEQkOVIIK3yNTqlnU8jU8CeDe7mIbuPlJJXtjRwcmkGWY6EIVv3QLSYazSaE5JGp5csRwJmowFRuYr1lnmUt/shKQuCHgh4huQ+u5vclLd4uGBmHrSWQXB4uqdqMddoNCckDU4fuSk28LvBVY8rebxKT7RnqwuGyDt/ZUsDQsB5k9PhX5fDU18ZknUPRIu5RqM5IWlw+shLtkL7XgBk+nhq2rsJJUZ7R3mGpiHg61sbWDAmnawdj0NHJSy4cUjWPRAt5kPAXXfdxSeffBJvMzQaTT9x+0NUtXkozUqCtj0A2PImEYpImsLJ0YuO3jNv7vKxu8nNeeOs8MGvYOwZMH7ZUa/bF1rMhwDdJVGjGV18tKeVYFhy2oRMaN0DCBJzJwLQRoq6yHP0Yr66oh2QXFL/O/A54Zy7hrwYqYeRmZr42g+gccvQrpk7A86/57CX1NTUxDokzpgxg4qKioO6I95///1UV1cjpWTevHlcffXVQ2unRqMZdt7f3UKSxcj8knTYuAdSikiyq2Ke9h4xdx99mGV1eRvXJ7xLavmLsOx/lQ4NE9oz70U4HGbLli2sWLGCXbt2cffdd/P73/+eSy+9lIcffhiA0tJSuru7MZvN/PnPf46zxRqNZqBIKXl/Vwunjs/EYjJAWxlkjCPZqprpOQOALW3QnrmUkqfW1FDW5CJx13+4XfwdJpwDp357CJ/iYEamZ34ED3o46emQ2Fd3xA0bNvDoo4+yYsUKLBYLCxcujJudGo1mcOxpdlPX6eWbZ4wHKaFtL8z8Isk2JYdd3iAkDS7XPByR/PA/W3hybQ2fs23lD5H7aEybR/7lfwfD8PrOI1PM40hPOX9f3RGffvppli1bhsViYePGjbS3tx9qGY1GM0JZXa7GLZw2IVMJtr8LMifEPPMuX0ilJw4im+XvH1Xw5NoavrywhEs2/oxamYnz8/8kP2F4+rH0Rot5L4xGY6zbYV/dEc8991xuvvlmdu7ciRCCuXPnHvQ6jUYzsmlw+jAZBAWpNqjeoA5mjMNqNmIxGejyBVXhUMPGAa/9YVkrE7Lt3LUgBBt38nrRtzi7OHeIn6BvtJj3oqioKNYh8VDdEZ944omDjt1xxx3DbptGoxkaWlx+MuwWDAYBrdE5BBmqx3iy1USXN+qZD3ADNByRrK/u4MKZ+fDZg2BO4rxrvgOG4cleORC9AarRaE4oWt1+Mu3RHikNm8GaAqklACRbzfs884ALgt5+r7u7yYXLF2JhYQJsfRZmfRFsqcPxCH2ixVyj0ZxQtLoDvcR8I+TNiuV+O2xmtQE6iJL+tVUdACwybIeQD6ZcPKR2H4kRJeZSynibMGwcz8+m0YwmWt1+1b0wHISmbUrMoyRbTbh8IZXNAgPaBF1X2U62I4HMhvfAYoeSU4fY8sMzYsTcarXS1tZ2XIqelJK2tjasVmu8TdFoTmiklPvCLC07IRyAvNmx88m2aJgl5pk39XvtNZUdnFSShih7E8YuBZNlaI0/AiNmA7SwsJDa2lpaWoamuc1Iw2q1Ulg4vJO/NaOPh97fiycQ5tazJ8bblBMCpzdIMCzJtFugYa06eIBn3uUNgSOageJq6Ne6Fa0e6jq9fH9OCPbUwdIfDLXpR2TEiLnZbKa0tDTeZmg0x5RXtjRQ1dbN/1s2QWVXaIaVVrcfUAMpqN+kwiHp42Ln922AZgMCXP3zzN/Y1gjAUtaoAxPOGVK7+8OICbNoNCciLS4/Tm+Q3c2ueJtyQtDiCgCoMEvDJsiduV9lZrLNTCAUwRcRKqPF3divdd/Y1sjMfAfJO5+GMaft8+yPIVrMNZo4EYnImKe4pkJXEx8Let7vbJtUYp4/Z7/zyVYVrHD5QuDI6Zdn3tTlY0N1J18rrIeOCphzzdAb3g+0mGs0caIzGr8F+KyyA7yd/f5arxkcLS4l5jnOzSp9sHT/Ae7Jtp6S/iDYc/vlmb+wsQ6As3xvQULyMU9J7EGLuUYTJ3qExWY2sqaiHfn01+AfF6jmT5qjp24dfPaX/d7PVrcfo0HgqP8IhBFKFu33Eoe1V7OtfnjmKz6r5p7XdnJhcRhH+Ssw/TKwJA79s/QDLeYaTZzoEfMzp2ST7CpDlK9UU28G0RPkRKc7EOJ/X9jK9tp2vC0VPPLks0T+cTG8+l346P7Yda1uPxlJFkTF+1AwD6zJ+62zf7OtXNUGN9L34Jkn11Rz+3+2sGRCJvfb/4EQBlg8vG1uD4cWc40mTrS41ZT286bl8jXjG4QNCWAwwbbn42zZ6CAckexuciGl5LkNdbz8yRaMj5yJ7Y+zuW7H1+mUSTDpAnj7J7DqPgh6aXUHKE4KQf16lQt+ALEwizeoNjFlpM/CoZW7mpWQT8zir3OrMJa/A2fdCWklw/vQh2HEpCZqNCcaPZ75wnwDduMqdmZfwLQkF2x/Hs76ybCNFzseeHFTPfe8uoN6p4/bz5/M6+vLeM52N9mRZu4NXUlekuRRzyKePG85/o6vUvD2T+DD33FbOA+D0aREeuzpB63b45m7fCFI7sk1bzwoO+UfH1VSkGbjz9fMxfTYDyFrMpx0/XA/9mHRnrlGEydaXH5sZiOZ7RuxiQDvJpwJ0z6vJrg3bIq3eSOav39UgRCCU8ZmcO/rO1nQ+jwlspaqc/5K0cU/4uSv/5a94Syu/PtmTq2+iQfH3A8zLscdtpAoAsorL1xw0LqxARU9G6BwUBVoJNodcfH4LBJdVVC7BmZfBYb4tsHWYq7RxIkWl+oRIpq2AvCROx8mfQ4QsPv1+Bo3wmly+lg4NoM/Xj2X/CS4wfwq4dKlTD51OVedXMykXAdzi1PZ0+wm2Wriwco8ak/9OV/0/5Cn5v4LvvJCn+X2NrMRo0Hs2wAF5Zn3Ynez6o44vyQNNj8JCJh++TF46sOjxVyjiRPNUTGnaSvtlny2tUWQielqY27P2/E2b8QSjkiaXH5yUxJIT7Lw/KIKMnFiPP17+11350XT+M7ZE/nNF2bR5QvxzSc2EJGSy+Yduq2GEEKV9PuCYI+K+QGe+dpK1R1xfkmqEvPSJZBSMLQPOQi0mGs0caLF5SfLngBN23ClTMTlC9HqDsCEs6F2LXTrQqK+aHP7CUckuSk2ADKrXlNT7w/oUjirKJX/XjaB0ydl4Ugwsammk/Om5VKSkXTY9ZNtZtWfxZQAtvSDPPN1VR1k2hMoDlepkNj0y4b0+QZLv8RcCHG1EOJFIcRzQojbDjgnhBC/EEL8TQjxRyHE9w61jkZzouP0BmN/b3H7yUsC2vYgc6YDqmET488CJOx9Nz5GjnAau1QWUG6yVaUN1m+A4lMOuWGcYDJy9lTlZd+4ZOwR10+xmWn3qLJ/HLkxz9wfCtPU5WNtVTvzS9IQlR+pa/rYSI0HRxRzIYQD+DKwXEp5CTBDCDGh1yVnA14p5dellN8EOoUQM4fHXI1m9LKqrJV5d71FWZMLfyhMZ3eQSYYakBHsxaoNa3mLW5WY29J1qOUQNDh7iXnrbgh6VGjqMHz77In86rKZzClOO+L60/KT2VTbSSQiIblAed/A/6zYyMm/eIeadi/zx6RB5YeQUhSbUhRv+uOZLwLekvsajb8AnNHrfDeQ0evnLOCUAxcRQtwohFgrhFh7vLa51WgOx8d7WwlFJG9ub6LNrTy/0nAlAGlj52IxGZRnbjDCxHNh81Pw2g8g6Iuj1SOPph7PPMWqqjwB8uce9jVF6YlccVJRv9afX5KOyxdSzc/y50Dzdsrrm3l9WyOfm5HHd8+ZyOVzC6DqIxizeMSkkPYnzzwD6B28awdinrmUcpUQYqoQ4hHABTQBB9WzSikfBh4GmD9/vq5X1pxwbKrtBOD9XS2cOi6DRYatlLavBXMSxvRSxmTUsrfFoy4+9xcqZvvpg5AxDhbcEEfLRxaNTh9moyAjyQJ161U/lOhA5qHgpDHpgBo2MbnwJJAR3n3nNSymbH66fJrquNi8A7rblJiPEPrjmbcBvb+bpEePxZBSPiylvE5K+f+ALqBq6EzUaEY/kYhkc60To0GwrrqD7a8+yBOWX5Bd9yYUzAWDgQnZDrbWOdXX+8R0uPD3YE2F5u3xNn9E0ej0ke2wqv7vdeuU92wYulyOonQb2Y4E1lW2Q+F8AJy7P+bSOQX7ZodWrlJ/HuPRcIejP+/Ap8BZQsS+S1wMfNDXhUKIFOAK4I2hMU+jOT6obPPg8oW4dE4BIhLk1Pq/U2ebCDe8C198HICzp+bQ2OVjXbVKfUMIyJyg+rWMQqSUvLmtkS89vJrmt+6DZ2+AUOCo123s8qkQS9CnZngWHD7EMlCEEJw0Jp01lR2QmE6HrYSZ7Oa6xdHhOdWrYeXP1beBtDFDeu+j4YhhFillpxDicWCFECIEbJRS7uw5HxX5PwARIBP4HymlZ7gM1mhGI5trnQB8ddEYrNtWUEIznef+dr+Nu7On5mA1G3hxY33sqz4Z46GiT99pROPsDvKD/2zmta2NnGf4jOz636sTZivywvvpDkZIShhcN5HGLh9TcpOheRtEggf1JB8K5o9J45UtDexqdLHbV8rp5o0kZ9uhowoeW642Rq9+esTEy6GfqYlSyhVSyiullNdIKX8DIIR4VghhlIpbpJTfklJeJaXULd80mgPYVNuJzWxkcq6Db6e8T2fKZFJnXbTfNUkJJpZNyeHVLQ2EwhF1MGMcdNVBYPT4R05vkAsf+JC3tjfxkzMyuc/yIBXWKbDoW7D+MZ75229YfO+71Hd6B7y2lJJGp4+cZCs0R33KaFrnUHLm5GwSLUaW/3EVnwTGkRzpVIMn1j4C4aCqIE0/cprjsWTQgSYp5WVSyr57Q2o0mv3YXOtkekEyJhki3VVG6vTz+vTqLp6VT5snwPyfv803/rVu38Ze295jbPHgWV3eRk27lz9fM4+vpWzAhp+fGr4BZ/0Ud/Y8ltY8QIa3As8flyKfuV5tYvYTlz9EdyBMXooVWnaAMWFYQh0lGUk8ddMppNosdGQtQCJg5S9h/WMw+QJI7V9mzLFEV4BqNMeAmvZuxmbalQBFgqpisQ/OnJzNfy0dR2Gajbd3NBNJ7xHz0RM331bfhUHAqeMzYdt/aE0cz/sdGXiCEe4MfJks4eQN64/IDVQR3Pka/HUZbHpy3wKNW8Ddd/pyUzTHPCfFCi27IHPisDW4ml6QwnvfW8qv/+tyxJLvwZanwNsBC24clvsdLVrMNZphRkpJuydAht0CDZvVwbxZfV5rNhr4/nmT+cK8IgKhCK0J0Z4fo0jMt9c7GZdlx+ZtgJpP6Rh7IVLC46ureLYxm72Fl2IwJ/DTlJ9xZdIjyJJT4bmb4INfw6Z/w0OnwyNn9Tnlp7ZDhWbyU6JhluzJw/osVrMRe4IJlv5AVeYWzFcDm0cgWsw1mmGmyxsiFJFk2BOgcTOYkyB93GFfU5Cq+o7UewyQXDjKxLyLqfnJsSEb9rlXAPDAu3twJJjIv+YhxK3bmb3oXNY3hdly+l9h6nJ4924l6vmzlWf+z8sg5N9v7R2NXQBMSBPgrIasScfmoQxGuPoZuPa1EbXp2Rst5hrNMNPqUYKU2eOZ504/Yl50flTM6zq8kDl+1Ih5hydAvdPHtPxk1Vsmeyq5pVNxWE24/SEunJWPzWoBawoXz87HajawYkMLXPEonstXUD35evjqS7D8D9C05aD+NDsbXBSk2khxl6sDWVOO3cMJ0Wfb3JGCFnONZpjpadqUnmiCpq2Qe+TWRQVpUc+806s2QVvLDjnoucsXJBCKDJ3BR8G2euU5T81LUcVOebMQQqhUQuAL8/e1n022mvncjHye31DHpppOrv0ojSUbz6TBa4DJF0FCCux4ab/1dzR0MSXPsS+TJWt4wyyjCS3mGs0w0+ZWnnleqAECbsg7spin2Mw4EkzUdXoheyr4u8BZ0+e1yx/4iHtf39nnuWPN9gaVTz89LQSuBmU7cM60HE6bkMmcotT9rv/OORNJSzRz6YMf81mF6hqyudapPOBJ58OuV1UqIOALhilv9TAlLxladqpMlvTSY/h0Ixst5hrNMNMabaqV5YkKbj88c1ChltoO777Ml8atB13T2R2gotXDyp3NQ2LrYGlz+7n+0TX8/aNK8lOspLrK1IkcJebXnzaWx687GXFAvDk/1cYTNyykINXGtaeOwWgQbK1THwhMuUhlj0RL5/c0uwlHJJNzk9VYvWHMZBmNaDHXaIaZnjCLvWM7GEyQ3b84b0GaTYVZsqcCQoVoDmBPsxuA8lYPzV3x6664tqqDt3c0k5po4WunjtnXTyZ72hFfOyYzife/t5Q7L5rG+Cw7W3rEfNyZYE6EnS8DKsQCMN3hUu1nJ547HI8yatFirhk6gl749CHwtMbbkiMSDEfYUN2Byxc88sVHSZvbT4rNjLFpi9qwMyX063X5qVYVZkmwq3BC45aDrimLijnA6or4TSbq+SB59OsnceOScapnii3toKn2h6LHY59ekMLWOidSSrAkQskiiA6B2NHgwmo2UFT1PMgIzLlmeB5mlKLFXDN0vHMXvHYb/O1cqPoEKj6EcCjeVvXJK5sbuORPHzPrp2/y5/eHuLpy+4vw3M2xplKtngAZiWaVydKPeHkPBamJOL1B3P6QKlk/hGduNRtwJJhYXd7WxyrHhqYuP0aDICMp+kHVvF3ZPMA0vhkFybS6A7FpQhQthJYdbC+v4u0dTUzOTsKw8Z8q11vHy/dDi7lmaKj6GFb/CSacq3KE/34ePHohrPlrvC3rk/IWNwYBhWmJfLRn8N8kpJR87+lNfFrehj8U5k+//A489WXYtEJt3gHt7gATEl3Q3drveDkckNGSOwPaK8Dv3u+asmY347LsnFSaHlcxb3b5yLInYDQIiERUv+/o5udAmFGYAsCWaGMyihYA8OtH/onHH+Ku6Y3QWQVzvzJkth8vaDHXHBVuf4h3ttbS+eQ38NsL4fK/wc0fwhcehbzZsOYvh0ypiyd1napZ0+RcB5ntG+E3kwbV/6TF5efpdbX84tUdvLd6DTf7HmFT0qmq0GeDam3b5vEzwxjNRBmQZ26N2uqNNpOSB/U239vsZkK2nZNL0ylv8cQyZ441TV1+spOjXrmzWmXt5AxczKfmpWAQsLFGDfKgcD4RYWSu2M0zN53MjB33QVopTP38EFp/fKDFXDNofvPGLube9RarVtxDancF33JeyabmEKSVwLTPw8JvqGKX8vfibepB1Hd6yU+1kZNsZbHnDXA3wicPDHidumjnv021Tprf/SMRBPeI62D2VbDnHXDW0uYOMIlokcsAOvwVpauBXX/9sJx2x0R1sFfc3OMPUdfpZXy2PebFt3mOvl/4YGjqUgMjgH2NswbwLaQHm8XIqeMzeeKzapzdQbAk0ZI0kXliN4VVz6kPs7PuHNHFO/FCi7lmUGyv7+KBlXs4f1wCP0p6AW/RErYmnsLN/1wXy7Bg6nJIzIDVD44477zeqcQ812HidLkGiSCy8QkaG2oHtE6PmNsNAS4Kv8NKw8ms7bARnHkVIJGv/YCE7gbG+XaolqnW5H6vne2w8vNLprOmsoMrn6wFi0MNMI6yt0W9z+OzHTisZoBjsqHbF80uPzk9nnnNpyoL5RDNxI7E7edPocsb5PfvqGetsE3jJOMuzK9/FwpP0l75IdBirhkQOxq6WFfVzu/e2oXDauKeSXsxBbqwnX8XD31lPh5/iPPv/4C/f1QBZqvyzsvegPd/FW/TY0QikoZOHwWpNqaGdpApuug66dsYQj5CD51B+J5S1fQpfGRhrIs2fvr15DJShYfwSTcSDEuqIlmw9HbY9SofJ/w3Yzs/Uk2aBsjVJ5fwX6ePY3ezh0jG+P3EvKypR8ztqhkUkL72Ptj23IDvczQEQhHaPYF9nnnNp2rohtE8qPWm5ifzxZOKefyTKtrcfjaaZmMmDBPOgS89OWJ7o8QbLeaaAfFf/1zHZQ9+wts7mrlpyVhsFW+pftJ5s5hekMI731nK3OI0fvfWbsIRCYtvhVlXwXu/gJ/nw98/F/dp860eP4FwhIJUKxPa38MvzZRNuJanIstojySxPlismj795cx9XQ4PQX2nF0eCifP4iEj6OApmnAnAnmYXLP0BVVe8xa+CX2TNgvvhc78dlL09sWh/ylhV1h+lyaXex4JUG8lWE4sNWyjd8n/w8R8GdZ/B0hKN0+ckJ6ghGg2bYxuXg+WcaTmEIpLKNg/vynl8K/MR+OI/ISljKEw+LtFiruk3oXCEmg4vp03I5LrFpXz95ByoeB8mnh/zlrIcCXxpQTEuX0gVeRgMcPEf1LT5mVdA1Sr46P6jsiMYjlDT3j3o1/d40/mpNrIb32dVZDobm0LcFriO/xv3V77guY31C+8HVyP85YxY978+1+r0MiklhKhchWHKRYzLsQP7vOZ6Swl/Ci8nOOnCAYVYetOT7teVVKpK+gPq2Z3eIBajAavZgN0c4aemf6gXNGxSOf/HiKZoGmFOshXqN4AMQ9HJR7VmT9fIuk4frZ4AobRS7ZEfAS3mmn7T2OUjHJFcMCOPOy6cSmLNKgj5YNJ5+123oFTNr/ysop0Pdrfw14+r4ZRvwkW/h2mXwqrfqTS7QXDfW7uZducbnParlWz4+C1Y+Qv45E/gd/V7jfrOqEebFMHirGBDZDyry1XBzVUnF2EyCN5mIXwzGi74z42xwpUDqev0cZ5lI0RCMOViEi0mClJt7InGs3vuFZvqPgiyHGqzr9VWrA5EOyh2eUMk20wIIUirfJ1xhgZ25F+qbBnA9J6jpadgKMuRoEIsoGLbR0FP18j6Ti8tLj9ZR/H+nShoMdf0mx6PtjCaOcHu1yAhGYoX7XddfqqNonQbH+9t5fb/bOHuV3awoWfi/Lk/B2GEd346KBte2dLA2MwkEkyCovdvhffvhTduh81P9XuNntmTRcFKAPYYSlhTqcR8Um4yE3McqqQ8MR2+9G81Iuw/N+wfQw8HYeerLO14hjN874AjPzZYeEKOnbImN3ua3fz8le0UpydSHM1MGQw9nnmDKTqqrE2FWrp8QZJtKi6d0LmHiBR8kH+9uqZm9aDvN1CaunrCLFaoWQMZE9R7dxTYE0yk2MxUtHhw+UJH9WF4oqDFXNNvejI3ClJtamjAjpfUplQfaWInl2bw9o5m6jq9WIwG7n19pyrRTs5XXvq256B+YLO/wxFJVZuH0ydl8ZXcWjL91QAxKdEAACAASURBVLD8j6psvGHTgJ7DkWAiqWMHAK1JE3B6gySYDOQlW5lekMy2+i5lb2I6nHO3Gqq840W1QMtu+L858O8v8X3+wTj3Opj8uViP8gnZdnY1ubjoD6swGgSPX7cAq3nwDaEy7Or9rZI5gIjFzbu8QZKjWSzCWUOTSKchkqoaUFV/Ouj7DZRmly9a/WlR3xr62XvmSOSn2tgc7dOS6dBifiS0mGv6TW2vWDO7XlUd7WZf1ee1J0dDLRNz7PzwgsmsLm9n5a5oZ79FtygBfuNHA+rjUtvRTTAsGZdp5wrxFk6ZSOuYC9UItgGIeU+OOU3b1DeLZOXxlmYmYTAIZhSk0O4JUN7q4Y8r9+AqPlOlFa5+UOV5P3YxMuSn9ry/sdh/P+vn3QOnfz+2/tlTc5men8wX5hfy7xtPoSQjqd+29YU9wYTFZKDZa4DU4lhGS5cvFPPM6aymSeTg8oVUvLrmU1WJeQxo6vKT7UjAgFTVmUM0YLkg1cruJhU+0575kdFiruk3dR1eMu0Jysvc8E9V5Th2aZ/XLp6QidVs4H+WTeSqk0sYl5XEnS9uwxsIgzUFzrxDbYb+bipsfKJf9y9v9QAwwe5lXNtKngmfzuqablWc0rw91gvliM/R6SU/1apayuZMIydFhY3GREV3eoEqKb/1yY38+o1dPL+xgfCCm6B2Dfx5MV1uDxd0fpcfbS+iVmYhZ14J9qzY+gtK03nhlsX8bPl0xmfb+2XT4RBCkGVPUK10MyfEPHOXN0iyVaUk0lFFqykHtz+oxNzXCe3lR33v/qAKhhJU//JwYMjEPD/VpjKiiE5p0hwWLeaaflPX6VXxcmedqm6cfdUh+0nnpdjYdOc5fG5mHhaTgZ9fMoOadi//9240te6k6+Abn0LhfHj51v1S7g5FeUtUzNtWYogEedm4jI/3tinPPBxQAwuOQCgcoaqtm6K0qGeeMz2W+leapcR8Sl4yRoNgU7Q/yAdlrXxoP5dnwkv4rfgKNyX/CUv+dN7frSbI92ReDCcZdgttHr8KobTtgUgEpzcaMw8FwFVPuyVPeeY9DagOMcxiKJFSsqfZrapVOyrVwSEU8x60Z35ktJhr+k1tR7cqG9/xIiBh1pWHvT7BtE/oF47N4NK5BTzyYUWsvzfZk+GyR1Rx0XM3QSR82PUqWt0kW00klb8KGeNJKZnJ+qoO1QMG+hVq2VTrxO0PsTTHBwGX8syTVbFLaaYSc6vZyIRsOxaTgaWTsvhkbxvPbe3kp8Zb+O8f3c+Kb1/EY9cuoCDVhtkoVBbHMJORZKGtxzMPdiO7aunyBUmxmVU8X0ZwWfNUh0V7tO2se/gHVtS0e2lw+lRYrSOaoTRE3Qx7f0gei/d4tKPFXNMvIhFJfaePwlQblL2l5lJmHH7C/IHctGQcgXCE/6zvVTKfnKeKaerWwZpHDvv6ilYPszIiiIoPYcrF5Kcl0ur2q3i2xQ6Nhy/wAVhV1ooQsMAatSF3BrkHiDnAbedN4r4rZnPlSUW4/SFe3FTPOVNzsZjUP5mURDP/uPYkfnvFbNUpcJjJsCeoZ82YAECgaTfBsFQboJ3VAHgSC5Vnbs9WL3I3DbtdqytUp8aFYzOUZy4MkFI0JGv3eOaOBNNRbSCfKJjibYBmZLKhuoMxGUmkJpr5/dtlZDkSCIQjlCQD61bB/K8PeM1JuQ7mFKfy7zU1XLe4dN8IsWmXwvrHVdVl1kRo2aWmy0QiUHwyLLkNzFbKWzz8T/p6VZQy9WIytlpo9wSIIDDkzuhXdsyqPS1Mz0/Bvv3/VN+YnOmcnWXijgunMrc4LXbdmZNzAFWYYxAQkXDhzLz91pqQ42BCjmPA78NgyLQn0OYOIDOnIQB/406glGSbSW06Aj57Ia6GECQ4VG+UYyHm5W1kJFnU3sCqSkgpHHQZ/4H0eOY6k6V/aM9ccxDO7iBXPPQJ1z26hhc31XP/O2X8+Hk1GGFqYAuE/TDhrEGt/aWTitnT7Oae13eyqiyaySIEXPBrCHbDY8vhtduQ7mZVkPThb2Hl3XQHQrQ43Sx1vwIpxZA3m/QkCxEJnd6gKu5p2Lhfv295QHMvtz/EhupOPl/QpfrFLLgJzFaSEkxct7i0Tw87xWZmdlEqyVYTp47PHNQzDwWZdguBcASXKR0Skom0qIyWmGcujETsearRlhDKOz8GYv5peTsnj01XH8wdlUMWLwcVWjEZhN787CdazDUH8c7OJoJhyfrqTm59ahNT8pIZk6GKXkraPwaTDUoWD2rtC2flUZBq46H3y7nmkU/3DSHInABfe4XHxtzDEv99rFz2ItzwDsy7Fj5+gNbPnuZHpn+R69oGy/4XhCA9Sf0jb/f41TzIcADKVwKq+dPie1fyr0+rYvdevbeNUERykfsZ5bkuuKFfNv9s+XQevGZeLMQSD3pyzds8QcicgCFaBZpsi4p5cgF2mxV/KEIgFFFxc1fjfmtIKXl7exOh8ABSFgOeQ+5l1LR3U9fp5eTSaL+UjkrVa3yIMBoExemJ5KUM/wbz8YAWc81BvLGtkZzkBC6dW4CUkl9eOoN/XLuAHy+ykVr+IpQuUZuWgyDRYmLV989g3Y/PIi3RzK/e2JeBUpc8k7vKSqiWOTz6cVSEz7kLUospfvtmrjW9gWfWtTDzC8C+ysg2dwCKT4GEFNj9OqA2a+s6vTzw7h6CUfH6rLKdeaYKsiqeg7lf7XeV4vSClLh65dD7WVXc3NIZFXOrCTqqIK0k1gZXbYJmH7QBuqayg+sfW8s7O4+8MfrMulq+9Ie3kPfPUlW2fbA5+kE8ryRNtVPwtAypZw7w0JfncfsFk4d0zeMVLeaa/fAGwry/u4Vzpuby68tn8f73zmB2USpjrB6ur7gVISNw9s+O6h5CCDLsCXzzjPF8WNbK/W+X8ea2Ru56SU3RufKkIt7f3UJ5ixsSHLRd8xY3h7/HYwU/Iemifa1093nmARWnHb8Mdr8JkQhV0UZcDU4fr2xuAGBjRRO/s/4FYc+FM24/qmc41vR45q1uP2ROwOptIgmvymbprILU4lgbXJcvCPacg8Ism2vV9J7qtgOalHW3q3z/aOtcXzDMva/vZEbjswhPC6x7tE/vvMEZbYuQlqg+UGDIxXxCjkN75v1Ei7lmPz4sa8EXjHDutFyMBqHyh8MhePpr6mv71c+olMIh4JqFJcwoSOG+t3dz4+PreH1bI18/tZRbz5mI2Sh4ZJVKdfvr2g7eCM3h1M/fsF/rgMxY6CHAq1saeMk3EzzN0LCBqmiBUW6ylb98WI7P281Xmu6lJFQJF96nCpdGET2NpmKFQ0CpaCDF6FfFOhnjcFh7xDwEjhxVONSr3fD2+i5A1Qt0eAKces+73PXydkIb/63SGz/4LUjJE59W0+Vycb3pNUIJqWoKUx/TohqdPmxmo9qEbd2lDmaMH8Z3QXM4dDaLZj821zoxCDh5bK8QxLt3QdVHcMnDqshniLCajbx4y6m0uPw0dvnItCeQl2JFCMGXFhTzz9VVTM518NcPy1k+K59xWftXU6b18sxX7mxm654CLjQbETteorL7CyRZjPz3svHc+9xq2h+6kwsN69g1/TtMOqDL42ggPcmCySBUf5yxaoTcWNGAw1OpLsiciN3SS8ztKhsHT7NqAQBsi4p5bYeXrfVO6jq9PLKqgq84/kqJ0QJNWwhXfsSf3/fx5cRPyI50svnkh5n52fdg07/VN59eNHT5yI3+vmjYBEYLZOmQSLzol2cuhLhaCPGiEOI5IcRtfZz/thDin0KIvwkhHhVCDL5FnCauuHxBHFYzZmP0fw1Pq5qNOftqmPXFIb+fEILsZCszC1PJT7XF0hW/e+4kshwJ3PHCNrIdVn568cGzM81GA8lWE21uP5VtHppCSQSKFsO256lqdVOSkcQlY+G5hJ+S2bGJbwVuIf3c7x+0zmjAZDQwMcfB1jonpI8lgoEppnosHdEh1JkTY0239isccqlQiy8Y7tWW10tF9JvLNyZ7KAnuJXj6D8GaiveDB2h1ebnF8iqbI6XstJ+iUkd3vnzQUJEmpy+Wo0/DJsieqmdzxpEjirkQwgF8GVgupbwEmCGEmNDrfCpwlpTyGinl14HtwNl9rHOjEGKtEGJtS0vL0D2BZkhx+UOx2CsAW59V/bFP+eYxtSPZauaXl84gL8XKH66aQ0pi37nLGdGeJTXtKn5bW3AedFRgbt3GmMxEEj+4m0JjO18O3M6mtLNGdSXhjIIU1c3RaKHROpY5xnLVdEsYIa20V5gleFDh0M5GF+GIJNuRQF2nl/IWD0kWI1cYVuKXJsryL4WTrsde8Rq/Nv+ZVF8ND4Yupsnlh5JTVdpox/496BujnjlSKjHPm3VM3w/N/vTHM18EvCX3Je2+AJzR67wTaBBC5AkhbEAJsOrARaSUD0sp50sp52dlZR14WjNCcPlCMVEAVBOs3JmQM+2Y23Lm5Bw+/sGZ+xXzHEh6koVt9U4C0YyVzfbFSGFkrmslkx1+2P48nqlX8qmcwrzDrDMamF6QTLsnQL3TR5llKjPkbmjeocrnTZZeG6C9wixulZ64rV5lnpw9NQenN8iWOifzMnwUVz3L8+HFbOs0wOm3UZ00k8uMq5Dp41hjXaRG0/WU5/f0XkFVBDf1iLmzRnXQ1GIeV/oj5hlAe6+f26PHAIiK/N+BbwA3AR9JKduG0kjNscPdW8ybd6hCnEO0uT0WiCOMCktPslDZKztjt8uCr+g0LjF8wAUtj0A4QPrp3+CnF0/jhiVjh9vcYaWnm+PWOifbjJNJwgt731XNtwB79Pfm9ocgKQsQsfTEbfVdOKwmTh6r/ulurOnkWl5EREI8zCXsbHSBKYGfJf6QLeaZiHPuJjM5UQ2e6MlQ6TUdqr07QDAsVZilpyeOFvO40h8xbwN6uzTp0WMACCFmAhdKKe+QUv4e8Aohrh9aMzXHCpc/GMtXZsfL6s/pl8fPoCPQuzow0WKkuq2b3VNuwUSY8TXPqJz4rIl8ddEYpuQNbgbnSKGnm+PWOifrpRJwgt2x7JYEkxGLyUCXLwhGEyRlxsIsW+ucTMtPjk2JSok4Oc35MmLWl0jKHc+uRheRiOSTJsEz0x+EyReQnWxVI+ESM8Di2M8zb3T2mvvZsFmFeuLw7U2zj/6I+afAWWKfi3Qx8EGv83lAb/fJC4wZEus0xxy3r1fMvHYNZE7ar1f3SKMn19xsFMwrSaOyzcNWw0TO99+DZ/o1cNZP4mrfUGI1GxmfZWdrnZOyQAZdxqiPFfXMQRURuX0h9YM9F1xN+IJhttd3MbsoTTVKAy42fowp4odTvsmkHAc7G7uoaPPgCYSZFv0GkONIUJ65EMo776hASkl3IBQT87wUq/r2ljUJzDofPJ4cUcyllJ3A48AKIcQ/gc1Syt6No98EwkKIx4QQfwGuAe4bFms1w04sZi4l1K096sG8w016tDKyKD2RsZlJVLd1s62+C6cpA9ulD6ieLccR0wtSWFvZQWOXnxr7THVwPzE3q141EOvPsq3eSSgimVOcSqY9AYvRwKXGD+nOmA45U5mcl0yrO8B7u1RiwoweMU+20uL2qwER6WOgo5J3dzYz9663YjNTc+0GqPoYihYcs/dA0zf9yjOXUq4AVvQ+JoR4FrhCShkGfjQMtmnigMsfUrHXjkroboPCkS2GGVHPvCQ9keKMJFz+EM+sq+XCmXkYjkFr2mPNxbPz2VDTQWd3kEDxEtjx2X5iXpieSFWbSjvEngMtO9lQrSo/5xSlYjAITkluYaa3At/suwGYnKs6P97/9m4SLcbYdKSc5ATCEUmbx0922hjY/SY7G5z4ghEeX12F0SDIbFsHATdMHH25+8cbgy4aklJeNpSGaOKPPxQmEIqofOXatepgwdAVCQ0HPWGWkoykWDOwQCjCTUsG1mt9tHD6xCze/c5S9UPkTDjnGrClxs6PzUxiXWU7UkqEIwfczWyqbic/xUp2NCf8UtMqQhiwzlF1A1Pzkkm0GMlLsXHnRVNjNQY91zd3+clOK4WwH0+rml7UHQiTl2LFWPYGmKxQevoxegc0h0JXgGpi9MRa7QkmFWIxJ6pCkBHMPjFPpCQq5mdOzmZS7rHpMx5XDEZw5O53aFxWEp5AmKYuP7n2HIgE2VNdy5zi4tg1SxL20mGcSVY0Fz0tycInP1iG3Wrarw1wzwSmZpdvv4wWIfKQEnKTE2D3a2qT2aLrBOON7s2iieGKirnDalKbn/lzVFbECGZijoMvzi/i7Kk5lGba+dqiMdx+/olbUl6aqUIk5S3uWK55uKuR2UVR711K0jx7yRo3e7/XpSSaD+rnnhOdjdrU5Y/lmltc1ZwyNoPURDPzklpVOE6HWEYEWsw1Mdz+qGduMarJ9flz4mzRkbGYDNx7+UwK0xIxGgQ/uXjaMZv+MxIZGx1KvbfVExPzLNHJtPxoWqanVRX49KOHSqY9ASGiaYgpRSCMOLprKclIZMUNC/mfrPVqTNyk84fteTT9R4u5JkaXT2VBpBm61TSh5II4W6QZKLnJVmxm436eeTadsaZktEQT0bImHXEts9FAtiOB+k4vGM3ItFKKQ5XkJtuYkm3DsX0FTDgXkvOH63E0A0CLuSZGT8w8NRIt+O3p76EZNRgMgtLMJMpbPKoNLsozj1X1xsS8f6GowrREajpUhW139hxmG8rITbbAzldUR8b51w75M2gGhxZzTYxYzDzcoQ709PfQjCrGZiWprogWO0GDlWzRua+qt2WXmsjkyDv8IlGK0myxJmYtqbPIEl2MMbXC2r+p0Mv4wc2C1Qw9Wsw1MXpi5kmBaLcG7ZmPSsZm2ant6MYfjuCxZJIlnPuqelt2qhDLEXre9FCUnkhjl49QOEKVTWU2jW18EyrehznXqIwazYhAi7kmhisaM7cFWtUBLeajkrGZSUSkGrjcZUwn1+Dcl6nSsqtf8fIeitISCUckDU4fZbIIj0wgc+Mf1MlZVw6D9ZrBosVcE8PlD2ExGTB1t6ipMdbUI79IM+Lo6dne6g7QYUwnR6gKULrbVZx7ANOAehpz1bR30+AOsZVxiIBH9Tgf4nmfmqNDi7kmhssXUtPe3S0qXt7Pr+KakUVqdJBHZ3eQdlLJICrmVR+pP3MPntp0KIrSVTFQbYeXRqePPZZoEZn2ykccI7siRHNMiXVMdDdF+2FrRiOpiSoNsbM7gIEUHHgg6IUN/1KdFEsW93utvBQrRoOgpqObBqeXzWlncXWqB6ZdMlzmawaJ9sw1MXrmf+Ju1pkso5i0Hs/cG6QxEg2VNW6Bsjdh9pcGVNVrMhrITbZS1dZNTYeXYMYUuOrfkHDiFmaNVLSYa2K4/b08c735OWqxmY1YjAY6ugPUh1Q7W567CWQYZl8z4PWK0m28vq2RFpefM6fo/y9GKlrMNTFcvhDJCQK6W7WYj2KEEKQmmnF2B/kwOJlVmV8AbyeMOxMyxw94vaK0RAKhCBNz7FwwvX/56Zpjj46Za2K4fCFyzCGQER1mGeWkJprp6A7Q6jfwwdjvsPi8hwa9VmGa2gT9n2UTj8se8ccLWsw1MVy+IHkGVe2nPfPRTWqihRaXH38ogiPBdFTFPZfOLSDBbOD86blHvlgTN3SYRQOAlBK3P0SmcKoD2jMf1aTazNR2qA/mWF+WQVKUnsjNp4/TXvkIR4u5BoDyVg8RCfmmLnVApyaOatISLTS7/AD7+rJojmu0mGsAeGt7EwAz7FEx1575qKancAhQM101xz1azDUAvLmtkdPyIiRv/AsUnQwJ9nibpDkKegqH4OjDLJrRgf4tn2B4/CFue2Yz358borj8SXA14pxwKTuq4ZX8f0CgGy7+Q7zN1BwlvT3zZB1mOSHQYn6C8faOJt7eUsXPKn8AdIE1lZSdL/Npgo3kdi+c8/MBddXTjEzSeom59sxPDHSY5QSgrtPLmb99j001nby5rYmbjS+REWykbflj8P82s8L+FdaZ5yKvfR0W3RJvczVDQIqtd5hFe+YnAlrMTwBe3lRPeYuHu1/ZTtmurXzT8hIvhRfySG0Re9v93N56HjsX/wFRckq8TdUMEWlJvTZAE7RnfiKgf8snAG/vaMJoEKyp7OAh86MYDUY+Hvdtnvuogu0NXRgNgsvm6eHNxxOpUc88wWTAYtI+24mA/i0f57S5/ayr6uD6xaVcnLSdc41rkUu+x3cuP4P8VBvv7WrhjEnZZDus8TZVM4T0bIDqEMuJgxbz45x3dzYTkXDhzHx+lv0e3YkFmE69hUx7Ak9cv5Czp+bwrWUDb76kGdlYzUasZoMaNqI5IdC/6eOcN7Y1kZtsZXpOAqJlHcz7KpjUWLHcFCt/+cr8OFuoGS7SEi06k+UEQnvmB7C1zsn66o54mzEkNHX5WLmrmYtn5yPqN0DIC2P6P2VGM7pJTbToMMsJhP7Y7kUoHOH6R9fS3h3gyRsXMqc4Ld4mHRVPrqkhHJFctaAYtr0ECDWIV3NC8IPzJ2MzD75bomZ0ocW8F29ub6Kxy4cjwcSNj6/jvXkfk9RdB8sfAOPo8nBC4QgrPqvmtAmZjMlMgooP1CDfxPR4m6Y5Rpw+UTdLO5HoV5hFCHG1EOJFIcRzQojbDjg3WQjx517/bRJCLBgec4eXRz+upDDNxoobF7LI8w5Jq38Lm/8NL/43SBlv8wbEuqoOGpw+vrSgGII+qF0DY06Lt1kajWaYOKKYCyEcwJeB5VLKS4AZQogJPeellDullDdLKW8GvgnUAGuGy+DhYk+zi08r2vnywhKm293ca3mELcZpsPR22LQCNj8VbxMHRL1T9bKenOuAmtUQ8kHpkjhbpdFohov+eOaLgLekjLmmLwBnHOLay4AXel0bQwhxoxBirRBibUtLy+CsHUY2VHcCcPbUHCh7Ayt+vt39VcomfwPSx8H6R+Ns4cBoifayznIkwK7XwGTVYq7RHMf0R8wzgPZeP7dHj/XF14DH+zohpXxYSjlfSjk/K2vkxfIqWj2YDIKi9ETYu5Kwo4ByCnhpSyPMuQaqPoK2vfE2s9+0ugMkmAzYLUbY+SqMPQMsSfE2S6PRDBP9EfM2oHdaR3r02H4IIZYBq6WUviGy7ZhS3uKhOCMRs5BQ8QHG8WewoDRDDW2Y9SUQBtj4RLzN7DctLj9ZjgRE8zZwVsOk8+NtkkajGUb6I+afAmcJIXoGAF4MfNDHdbcAfxoqw4415a1uxmbaoWEj+Dph7BnMKkplb7ObUFIOjD8LNj+530ZoJDJyN0V7xJydrwJCi7lGc5xzRDGXUnaiQicrhBD/BDZLKXf2vkYIMQuok1K2Do+Zw0s4Iqls62ZcVhKUv6cOlp7O+Cw7gXCEmg4vTL4QnDXQvIOP97Zy0R9WMfHHr/Gf9bVxtf1QtLj8ZNkToOwNKJwP9ux4m6TRaIaRfqUmSilXSCmvlFJeI6X8DYAQ4lkhhDF6fpOUctQ2wq7v9BIIRRjbI+Y5M8CexfhsNTqtrMmlPHOAPW/z3Po69ra4MRsNrK0amdWirW4/RTY/1G+AccvibY5GoxlmBl3OL6W8TEoZHkpj4sXeFjcA41KNUL0axp6ufo6K+Z4WN6QUQPY02PMWDU4fE3IcTMp1UNvaCR2V8TK9T4LhCO3dAWaHtoCMwLhDJR9pNJrjhRO+N4s3EKa8xQPABP8WCAdi4pdsNZObbGVPsxJ7JpwFVZ/Q2dlGfoqVMek2vt5wN/zfXKj+NF6PcBDtngBSwqTutWBxQMG8eJuk0WiGmRNazD8sa2Hana/zj48rSbaaSK5bBUYLFC+KXTM+287eHjEffxZEgpR2rSU3xcq5kQ9ZGlmNNJrhma9Dd/sh7nRs6ckxL2xfDaWnjbpWBBqNZuCc0GL+9vYmIhKq27sZm2VHVLwHRSeDJTF2zfhsO3tbPEgpofgUIolZXCTfozQxwLLK37AuMoHa5c+Auwn+9QXwxj+G3uLyM0Y0kOipUfnlGo3muGfUinkwHOHul7fT1DX4tPbV5e0sHp/J7edP5lsnp0LjFhi7dL9rxmXbcftDNHb5wGimfdIVLDOs54zK+zAHXfwweB27TRPhC/+Axs3w6MXgdx3Vsx0tLS4fPzE9RsRk1SmJGs0JwqgV8231Xfx1VQWvbG4Y1Ovb3H52Nbk4ZVwGN50+jjNNm9WJcWfud934rJ6MFhVqKSu8DAEU1bxAYPJydsliKlo9MOVC+OK/oGkrvHBLXBtzZe/+F0uNmwgv+xmkFsXNDo1Gc+wYtWJe29ENQFlPPHuAfFah4tsLx0Y7E+x4EZILIX/OftdNznUAsLXeCUBFKIv3IzORwoBl2Q9xWE1UtSlbmHgOLPtf2P48PHw6PHsDhPyDsm+wyO52FpY/wCdyBuaFNx7Te2s0mvgxisVcdQXc0zy4kMbq8jZsZiMzC1PA74Y978CUiyBW6KpIS7IwNjOJ9VWqEVej08udoWuJfHEFImsSpZlJVLZ59r3g1P8HS25TG6lbnoLKDwf3gP2kpr2bu17eTiAU4bOKdv72q29jCXt4JPH6g55Fo9Ecv4xaMa9pV97w7iY3fTRpPCKfVXYwf0waZqMByt6EsF+JeR/MLUljfXUHUkrqnT4CjmKMk88DoCQjaZ9nDkpAz/wRfPUl1amw7O2BP9wAeHpdLY+squDdnc28+slGrpKv8mL4FLpSJw3rfTUazchi1Ip5j2fu9AZp7ehQqYE7X+n36xucXkoyolkrO16CpCwoXtjntXOL02j3BKhq66bR6SM3xRo7NzHbTk1HN39bVYGUkkanj9+9uYt19T41b3PP8Ir5uioVLnpmXS2O3c9iEwFa5v4/Lp9XOKz31Wg0I4tROzautqObFJsZpzeIZ9Wfydr6LGz9D3zuN3DS9Yd9bSgcwekNkp6kptRT/Yna+DT0PS9xbkkqAOurO6h3emNxdICvLy5lS52Tn728nd+9tRt/KEwwLNnbUzek5AAAFFdJREFU6mHe+LPg9R+oCtG0MUPx2PsRDEfYUN2JySB4e0cT/2X5lK6MadxwyblDfi+NRjOyGZWeuZSS2g4vSyZmkYSX3C0PQenpMPFceOW7ULv2sK/v9AaREjKSLOBuAVcD5M065PUTsh04Ekysq+pQnnmyLXYuKcHEn6+Zx72XzeCK+UV8/dRSZhelUtHi2dfPpeytIXnuA9nR0EV3IMzXFo0hiw7mGcqwzVw+LPfSaDQjm1Ep5i1uP/5QhPklaVyX8C7WYCcsuxMu/QvSkUfD4zewobL5kK9v9wQASE+yqNxwgNwZh7zeaBDMLk7lqbU1dAfC5Kda9ztvMAi+eFIx/3vRVG6/YApzilOpaPUQSRsHKUVqsMUwsKZSFShdf9pYvpK2FQDztIuH5V4ajWZkMyrFvCdeXpRu4yzLVsrN46FwHliTqTv1LvL85RQ+eS7/v707D46jvhI4/n0jzUia0X1Yh3X4Ehjb2GYxGBvHXAkk2SxXtkhSSaq2agMhN7nIsUvVVshmKZLUkmwVEMi1IZSpbEhCuDYmgYIsxAaDAeMLX7ItW5J1y9KMNdLot3/8euSxPDosz0yr5fepopC6p2eemtbTj9e/fj82/yTpfO/OfpvMy0IB+6AQQOWyCT/zM1cu5MaVc7n9ioXcsHLuhK9dUJFPZChG6/FBqDgfuvZP46ec3JamLmpL8qgqyuWz1bswpYugYnFaPkspNbN5smYeT+a1xXnUjhzgyaFVSMcA88tDvCiX8Eb0dj6X+xIVz95pH+L50H2n1MNHR+b5TjIvqoNg6YSfuXZhOWsXlk8pvoXldnm2Ax0D1JTMh8Ov2j8qKZ4quPVQD5ctKAVjyGreAis+qtMRlTpHeXJkHp+WWOvrIhjrY49vPt94/G1GRgyvN3Xz+Mh6vhS8F9Z/Hd74Fbx83ynHdw3YB3lK4yPzCUos07HAeWp0f3s/lC6Awb6UN+EKR22LgcbKArtoRvQ4VC5J6WcopbzDk8m8uTtMWShAsGsHAJetvZJXD3Tx29ebef2QrSM390Tg6n+FhnXw1mOnlFs6nZF5iX8YOvekPJlXFuYQDGSxr30ASufbjSkutRxy/qDVlwahzZ4H5ixN6WcopbzDc8n8UGeYp95qsU9utm4DhGuuuIqVdcXc+6ddHOwMU56fQ3d4iP7BYVh6I3S8C8d2jr5H10CUojw//o7ddvGGquUpjVFEmF8esj1bShfYjd0HUvoZTR02mTeUBeFYPJlrvVypc5WnkvlQbIQvPrYVBL5zwzI7E6VsEZJTwJ3XnU+Hc2Pz+hU1gNO/5YLrQXy2X4qjcyBqb34edhaUqFmZ8lgXVOSzv6MfihsAScPI3LYQaCgN2T9UhbWQW5TSz1BKeYenkvmWpm62HenlnpuXU1catMncKZGsXVTO5YvKyPX7eP+yKgCauyJQUAkNl8P2k8m8eyBKSSgAB160I+ei1D8tuaA8RHN3hBP4oXAudKV2ZH6w0z40VRT025G51suVOqd5KpmvWVjGC1+9kr9fXm0Xgeg5dEq9+z8/spJHP3WZXZiZk50VWXIDdOzm/t8+y7PbWugaiFIezIKml+3DRmlQVxrEGGjtPWHr5mmomTeUBSE2ZMtIcy5I6fsrpbzFU8kcoD7eT6XVPiRD9cl695yCXC5uKKEsFCDX7+OwM4WR8+zj7d1vPsUjmw7SORBluW+/nQGyID3JvCRol2rrjQzZZJ7imvnBzrC9+dm5z65bqjc/lTqneS6Zjxp9cvP0m5ciQm1J8OTIvLieaNlirpI32Hqoh+6BKBdG37T75q1PS3jFTjLviQzZUs5Ae8pWIBqKjXCkJzLm5qeOzJU6l3k4mW+D/CrIn5N0d21JHs3dEY6fGGJkxNBauZ5LfLu5NvYiv8v+Npe2PmZLNKGytIRXlBcAoCccPTmjpWNPSt77aE+E2Ig5efNTsqD8vJS8t1LKm7ybzFvennB+eF1JkB0tfVz4bxt58KV97Mxfg19i/ChwPyFOcLyoEdZ8IW3hFeUllFniccb/b+Isxfun18dH5mULwZ87yVFKqdnMm8l86AR07D6lXj7WdUuruGx+GXMKcvjbvk62xBbRZkp4VxZwU/Q77Lh2A6z4SNpCHE3m4SEomQ85RdDyVkre+2DXmDnmWmJR6pznyd4stO+CkeEJR+brGstZ11jOt373Ns9sayUnO4vPF/6Y+bU19G1ts/PM0yiQ7SMUyLI1cxH7h+fomyl57+auMIEsH5U5MTvlcflHU/K+Sinv8ubIfIKbn2Mtry2mNzLE5gOdFJXXsG5xDYFsHzXFeZMee7aKgwF6wkP2m+oV0LbdTiU8S83dEeaW5OHrfBcwOjJXSnl0ZN66DQL5tnwxiQvn2qcij58YpqEsyD8sr2bdonLbZCvNCvP89EbsU6lUr7TrjLbvhqqJ2+1Oprk7TG1JXsJMFn1gSKlznTdH5s1b7EjXN3n451cVEMi2r2soCyIiGUnkAMV5/lNH5jBaN3/jUPfo+p1nqrk7Qm1J0M5kyc492cxLKXXO8l4yj4ZtmaVu9ZRe7s/ysaS6EICGslA6IztNcdBva+bgzDgJQYutm3/tN2/x70/vnODo5AYGh+kciJ4cmVecP+7apUqpc4f3kvmR1+3Nz/rLpnzIilpbamkoDaYrqqSKg3bBacAm3PrVsOsZmtp62N8xYLs6nqEjPc4qSyW5ttykT34qpfBiMj+0yf677tIpH3LT39Vy/Yoa25wrg4ryAvSGhzDxXuqrb4e+Zg6+9GsABgZjEx7f2T/ItubeU7bFn2o9b3i3fap04VWpD1wp5TlTSuYi8nER+aOI/F5E7kyyf6GI/Nz552ERqUl9qI7Dm6DiAsgrmfIhK+uK+fHHLiLLl9kl1Yry/ERjI0SGnKS96H1QcQHz3/0pYBiITjwyv+/Pe/jHB19hIGEEP7r+aetfwOeHxmvTFb5SykMmnc0iIgXAJ4EPGGOMiDwiIo3GmD3OfgHuAT5tjBn3jp6I3AbcBlBfXz+9aEdicPg1WHbT9I7PsNH+LOEhgoFs8Pk4cennqH/68zzg/xFPRdfBK+/CJf8M/tOnSm470svg8Ah/3dNBdVEuf9reSnR4hJxsIbjvGdskLK840z+WUmoGmsrUxLXAc2a0VsATwFVAvNHIJcBh4HtO4n/BGPPTsW9ijHkIeAhg1apVZuz+KTm2EwZ7oX7NtA7PtOK8k8k8Pq/9+60XERj6KF/xP84HeBU2AoU1sOzmU44dGTHsbrWNuZ7b0cb+jn62HuqhJC+bDxXsRboPwLo7MvrzKKVmrqmUWcqAxBF3l7Mtbh6wDLjDGPNx4GIReU/KIkwULIWr74J56Xn7VCtKbIMLPLr5ID97+SCR1V/kd5c/wcei/2Jf2N102rEHu8JEhmIEA1k8+fZRth7qIZQV41exO/lh5C47z/78D2bqR1FKzXBTSeadQGKButTZFhfGjtxPON//Ebg4NeGNUVgD678GRXPT8vapVux0TuyNRDnaE+Hup3aw/rwK7vrQEiiu428jS4nllSdN5jtb+gD4xGUNRIdHKAn62bBqDxf6mthY/Wn4zCvjdoxUSp17ppLMNwPvdWrjANcDLyXsfx1InFqyGkhNe0CPK0qomd/z7C6Mge/dtIwsnxDKsRWuaGF90mS+q6UPn8Ct71lAQU42t11ey4UHfs7RwuVUffBbUNKQyR9FKTXDTVozN8b0iMgjwAYRGQbeNMbsStjfIiIbRWQDMAA0GWOeT1/I3hGvmW/c0cbzu47xxWsa7ZObQChgT30kVEde19bTjt3RcpwFFflUFOTw8reupuCdR5G+Zmo+8SNq6qY+k0cpdW6YUm8WY8wGYEPiNhF5HLjFGBMzxjwMPJyG+DwtGMjCnyU8v+sYdaV53H7FglP2AfQHayk98KRtwJXlH92/s6WPi+rtTJXCnGzYdL9tCbDwmsz+EEopT5j2Q0PGmA8bYyZ+6uUcJyKjKw7dc/NyOz3RES+z9ObOBTMCvYdH9/WdGOJIT4QLnDYE7H/B9m9f/RnbTlcppcbwZtdED1mzsIzKghwuX1R+yvZ4Mu8OOM9XdTeNLi+391g/AOdVFth9mx6EUMVp0xeVUipOk3ma/dfHLkq6PZRjyyzt/oRk7tjbZpN545x8iPTAno3wnq9Adk5aY1VKeZf3erPMEvEboB1SAlmBU5N5ez+BbJ/tJXNsB2A886CUUsodmsxdkufPQgQGogaKT52euKftOAvKQ7aXTOs7dmOldkdUSo1Pk7lLfD4h6M+ifzAGJfPsWp6Ove39LJqTb79pe8c2FSuodidQpZQnaDJ3USgnm3B0GIpqoe8IAJFojObuCI1znJufbduhcpnOYlFKTUiTuYtCOdl2gYrCWgh3wlCEfe39GIMdmY/EbM288uzWDFVKzX46m8VFoZwswtHYyV4zfUfZ154LQGNlvq2jD4W1Xq6UmpSOzF0UDGTbhScKnWTe28yetn6yfMK8spCtlwNU6chcKTUxTeYuys/JtqsNFdXaDX1HeK2pi8Y5+QSyfXaNT/FBxWJ3A1VKzXiazF0UDGQRHozZ1r5AuP0grzV1ce3SKvuCpv+DquVJVyFSSqlEmsxdlB+/AerPg2A5LYf3MmLguqWVMHgcml/TBZuVUlOiydxFwUC2vQEKUDSXgfZD1JXmsaS60I7KR4Zh4dXuBqmU8gRN5i7Kz8liIDqMMYbh/Bpywi1ct6QKEYF9z4M/CHWr3Q5TKeUBOjXRRcGcbIyByFCMsH8O1XRy6fxSu3PfC9CwVptrKaWmREfmLgrFF6gYHKYzq4JCCVMbjEH7bujcowtRKKWmTJO5i+I9zcODMVpNGQA10gmbHoDsXFh+i5vhKaU8RJO5i+IrDw1Ehzk0Ytf1LGrbBG89ZhN5qHyiw5VSapQmcxflOyPzgcEY70Tn0kkx8uzXYThil4hTSqkp0hugLoqvNtQXGeJAv5+vVT7MLxZvAQQql7gbnFLKUzSZu2heWQiAfe39tPRFuLi+Aq76tstRKaW8SMssLioJBaguymX70T7aegepKtLH9pVS06PJ3GVLqgt5ZV8H0dgI1UW5boejlPIoTeYuW1JTSEd/FIAqTeZKqWnSZO6yC6oLR7/WkblSaro0mbtsSUIy15G5Umq6NJm7rL40SCiQRbZPKA9pHxal1PRoMneZzycsri6ksjAXn0/cDkcp5VE6z3wG+MLVi+gaiLodhlLKwzSZzwBXnj/H7RCUUh6nZRallJoFpjQyF5GPAx8BYsDfjDH3jtm/FdjsfDsMfMEYY1IZqFJKqfFNmsxFpAD4JPABY4wRkUdEpNEYsyfhZZ3GmNvTFqVSSqkJTaXMshZ4LmGk/QQwdsn4LBH5DxF5VERuTPYmInKbiGwRkS3t7e1nEbJSSqmxplJmKQO6Er7vAhoTX2CMuQpARPzA/4jI9jEjd4wxDwEPAaxatUpLMEoplUJTGZl3AiUJ35c6205jjBkCngOWnn1oSimlpmoqyXwz8F4RiT/Rcj3w0gSvXwO8ebaBKaWUmrpJyyzGmB4ReQTYICLDwJvGmF2JrxGR/wYiQD7wB2NMUzqCVUoplZxMdwahiDwO3GKMiU3j2Hbg4LQ+2CoHOs7i+HTRuM6MxnXmZmpsGteZmW5cDcaYimQ7pp3M3SQiW4wxq9yOYyyN68xoXGdupsamcZ2ZdMSlT4AqpdQsoMlcKaVmAa8m84fcDmAcGteZ0bjO3EyNTeM6MymPy5M1c6WUUqfy6shcKaVUAk3mSik1C3hqcYrJWvFmOJYHgBFse4OnjTG/FpE/A3sTXvZNY0xPhuNK2o5YRN4LfBkYAJqNMV/JcFyLgTsSNq0BbgV+kizeDMSTBXwHuNgY835nW9JzlMlzN05c38VeZyFgmzHmB872nwEBJy6A7xtj9mUwrqTXu4isAL4H9ANh4Dan1Ufa4xKRCuDuhJcsA35sjPlNpn8/x8kR6bvGjDGe+AcoAP6Xk3X+R4DGGRCXAH91vv7zDIjntBicGP8C5Djffxd4n4sxZgFPOXG5cs6AG4DV8c8f7xxl+tyNjSvJ/j8BIefrXwK1bpyv8a41Z/vTQKnz9aeAW108X48DwYnizcC5E+Cv6b7GvFRmmUorXjfkcLKrZL+I3O30fL/VpXiStSM+D9hhjBl0vv8D7p67DwNPOP8tJ22fnA7GmCeMMZsTNo13jjJ67pLENcrpjzSCbZ0BdhR3h4j8UkS+KSJp+30eJ67TrncRyQWGjTHx3wk3z9elwE5jTHi8eDMkniPSeo15qcwyaStel3wXuBfAGHMjjP7SPSAi+4wxz2cyGJOkHTHJz11ZJuMa45+Am2Fq7ZMzZLxzNJPO3ZeAXxhjRgCMMZ+L7xCRb2PP688zFUyy6x3YBSSWLrqwZQY33AGMlitc/P2M54i0XmNeGplPuRVvpojIl4GtxpiXE7c7I84ngeWuBMZp7YhnzLkTkWuATcaYE4nbjfvtk8c7RzPi3InILUDAGPObcV7yBC5db2Ou92TnqyvZcekkIo3AgDGmdey+TP5+jskRab3GvJTMz7QVb1qJyGexF8uj47xkPfBaBkNKJt6OeC+wTERynO03AC+6FNPngfvH2edm++TxzpHr505EbgCWmIlv+F8BvJqhkJJZD7zmlAr8IhJPTm5da18F7ptgf9p/P5PkiLReY54ps5gptOLNFBFZC3wTeEZEHnQ23+Vsywdygc1jR+wZii1pO2IRuRt4VET6gXZgowuxrQCOGGM6Era53T55CMAYE0t2jowxxqVzNwQgIg3YpwV/n3Ct3WeM2eWUVuZhbygfNsaM90cy5XE5sf2Q5Nf7N4CHRaQPZ4ZShuOaA1QYY7YnvmCCeFNughyRtmtMnwBVSqlZwEtlFqWUUuPQZK6UUrOAJnOllJoFNJkrpdQsoMlcKaVmAU3mSik1C2gyV0qpWeD/Aad/r+1hEsfJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "plt.plot(y_test)\n",
    "plt.plot(y_pred)\n",
    "plt.legend(['pred', 'real'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buzYEhw3gkH_"
   },
   "source": [
    "# Bidrectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 754,
     "status": "ok",
     "timestamp": 1578895692034,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "rbk7s8xDcU32",
    "outputId": "df010de2-9480-47e7-cdb2-d0f739e8f0c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alex/venvs/tensorflow-1x/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/alex/venvs/tensorflow-1x/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/alex/venvs/tensorflow-1x/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cell = tf.keras.layers.LSTMCell(32)\n",
    "lstm = tf.keras.layers.RNN(cell)\n",
    "\n",
    "X = tf.keras.layers.Input(shape=(7,5))\n",
    "net = tf.keras.layers.Bidirectional(lstm)(X)\n",
    "Y = tf.keras.layers.Dense(1)(net)\n",
    "\n",
    "model2 = tf.keras.models.Model(X, Y)\n",
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1578895718595,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "UXG8J1TwhE2j",
    "outputId": "285f5909-ca28-4f63-c3f1-5c3edb725e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 7, 5)]            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                9728      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 9,793\n",
      "Trainable params: 9,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11707,
     "status": "ok",
     "timestamp": 1578895812674,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "rONAtlr1hGiz",
    "outputId": "b3015260-a2d5-4041-e614-0a0d0dc1f49e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 1s 2ms/sample - loss: 0.0883\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 0s 274us/sample - loss: 0.0165\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 0s 271us/sample - loss: 0.0068\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 0s 265us/sample - loss: 0.0035\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 0s 275us/sample - loss: 0.0027\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 0s 266us/sample - loss: 0.0026\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 0s 266us/sample - loss: 0.0026\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 0s 292us/sample - loss: 0.0025\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 0s 274us/sample - loss: 0.0025\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 0s 268us/sample - loss: 0.0025\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 0s 271us/sample - loss: 0.0024\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 0s 266us/sample - loss: 0.0024\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 0s 270us/sample - loss: 0.0024\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 0s 272us/sample - loss: 0.0024\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 0s 270us/sample - loss: 0.0024\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 0s 274us/sample - loss: 0.0023\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 0s 264us/sample - loss: 0.0023\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 0s 268us/sample - loss: 0.0023\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 0s 268us/sample - loss: 0.0023\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 0s 269us/sample - loss: 0.0023\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 0s 283us/sample - loss: 0.0022\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 0s 290us/sample - loss: 0.0021\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 0s 279us/sample - loss: 0.0021\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 0s 319us/sample - loss: 0.0021\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 0s 262us/sample - loss: 0.0020\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 0s 278us/sample - loss: 0.0020\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 0s 326us/sample - loss: 0.0020\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 0s 314us/sample - loss: 0.0020\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 0s 288us/sample - loss: 0.0019\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 0s 297us/sample - loss: 0.0019\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 0s 272us/sample - loss: 0.0018\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 0s 268us/sample - loss: 0.0018\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 0s 264us/sample - loss: 0.0018\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 0s 258us/sample - loss: 0.0018\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 0s 268us/sample - loss: 0.0017\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 0s 267us/sample - loss: 0.0017\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 0s 266us/sample - loss: 0.0017\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 0s 288us/sample - loss: 0.0016\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 0s 358us/sample - loss: 0.0016\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 0s 354us/sample - loss: 0.0017\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 0s 281us/sample - loss: 0.0016\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 0s 338us/sample - loss: 0.0016\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 0s 359us/sample - loss: 0.0015\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 0s 271us/sample - loss: 0.0015\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 0s 359us/sample - loss: 0.0015\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 0s 358us/sample - loss: 0.0015\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 0s 307us/sample - loss: 0.0016\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 0s 341us/sample - loss: 0.0015\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 0s 325us/sample - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1418dad68>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ztp66fP-ixq_"
   },
   "source": [
    "# 다음 문자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60VQN7GShVSr"
   },
   "outputs": [],
   "source": [
    "contents = \"\"\"\n",
    "여린 부리 파랑새\n",
    "사랑이라는 빛 하나 문다\n",
    "\n",
    "바람 지나는 밤낮\n",
    "나의 온기속에 그대 심장을\n",
    "그대 온기 속에 나의 심장을\n",
    "\n",
    "미소도 눈물도 두 심장\n",
    "하나의 맥박되어\n",
    "\n",
    "덤불 어지러운 미물의 제자리걸음\n",
    "빛으로 이끌어내며\n",
    "사철바람 타고 날개치는\n",
    "\n",
    "고운 부리 파랑새\n",
    "사랑이라는 빛 하나 싣고 간다\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1578896595048,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "Dqg7fxHCjN_7",
    "outputId": "22a15917-f379-4a86-9bef-5f6f3e85ea85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['으', '자', '는', '장', '러', '싣', '\\n', '도', '간', '사', '빛', '며', '제', '바', '되', '철', '린', '소', '눈', '람', '지', ' ', '기', '낮', '맥', '심', '걸', '운', '끌', '온', '랑', '파', '미', '다', '밤', '대', '불', '음', '치', '로', '새', '을', '라', '여', '나', '어', '리', '그', '속', '박', '이', '두', '개', '덤', '의', '에', '하', '문', '타', '날', '내', '부', '물', '고']\n",
      "{'으': 0, '자': 1, '는': 2, '장': 3, '러': 4, '싣': 5, '\\n': 6, '도': 7, '간': 8, '사': 9, '빛': 10, '며': 11, '제': 12, '바': 13, '되': 14, '철': 15, '린': 16, '소': 17, '눈': 18, '람': 19, '지': 20, ' ': 21, '기': 22, '낮': 23, '맥': 24, '심': 25, '걸': 26, '운': 27, '끌': 28, '온': 29, '랑': 30, '파': 31, '미': 32, '다': 33, '밤': 34, '대': 35, '불': 36, '음': 37, '치': 38, '로': 39, '새': 40, '을': 41, '라': 42, '여': 43, '나': 44, '어': 45, '리': 46, '그': 47, '속': 48, '박': 49, '이': 50, '두': 51, '개': 52, '덤': 53, '의': 54, '에': 55, '하': 56, '문': 57, '타': 58, '날': 59, '내': 60, '부': 61, '물': 62, '고': 63}\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "char_set = list(set(contents))\n",
    "print(char_set)\n",
    "\n",
    "char_dic = {c: i for i, c in enumerate(char_set)}\n",
    "print(char_dic)\n",
    "\n",
    "char_len = len(char_set)\n",
    "print(char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1578897295303,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "EtuqfqLgjeBU",
    "outputId": "3f65c4f8-5347-4a4a-dc38-2a9237877a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 10) (150, 10)\n"
     ]
    }
   ],
   "source": [
    "data = [char_dic[w] for w in contents]\n",
    "x_data = np.array([data[i:i+10] for i in range(len(data) - 10)])\n",
    "\n",
    "#import pprint\n",
    "#pprint.pprint(x_data)\n",
    "\n",
    "y_data = np.array([data[i+1:i+11] for i in range(len(data) - 10)])\n",
    "\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1578897297008,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "w2ycwrSHkklD",
    "outputId": "a43eadbd-82ad-444a-9b21-597f57996fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 10, 64) (150, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "x_data = tf.keras.utils.to_categorical(x_data, char_len)\n",
    "y_data = tf.keras.utils.to_categorical(y_data, char_len)\n",
    "\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AQDiokrmueV"
   },
   "outputs": [],
   "source": [
    "cell = tf.keras.layers.GRUCell(64)\n",
    "\n",
    "X = tf.keras.layers.Input(shape=(10, char_len))\n",
    "net = tf.keras.layers.RNN(cell, return_sequences=True)(X)   # return_sequences=True 이면 중간의 hidden_state 값도 return함(차원이 하나 더 생김)\n",
    "net = tf.keras.layers.Dense(char_len)(net)\n",
    "Y = tf.keras.layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1578898107192,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "06qc5j_0oGzT",
    "outputId": "204bebeb-768b-4004-fc6e-9b6ad7735657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 10, 64)]          0         \n",
      "_________________________________________________________________\n",
      "rnn_4 (RNN)                  (None, 10, 64)            24768     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10, 64)            4160      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 64)            0         \n",
      "=================================================================\n",
      "Total params: 28,928\n",
      "Trainable params: 28,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45031,
     "status": "ok",
     "timestamp": 1578898155968,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "lV1IFfPvoIVU",
    "outputId": "f408bf2e-7b54-43d2-f94b-3c320536a5aa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 4.1472 - acc: 0.0140\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - 0s 294us/sample - loss: 4.1155 - acc: 0.0900\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - 0s 334us/sample - loss: 4.0822 - acc: 0.1780\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 0s 298us/sample - loss: 4.0454 - acc: 0.2300\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - 0s 331us/sample - loss: 4.0015 - acc: 0.2420\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - 0s 331us/sample - loss: 3.9451 - acc: 0.2427\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - 0s 337us/sample - loss: 3.8678 - acc: 0.2227\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 0s 328us/sample - loss: 3.7578 - acc: 0.2133\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - 0s 330us/sample - loss: 3.6874 - acc: 0.2113\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - 0s 321us/sample - loss: 3.6376 - acc: 0.2167\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - 0s 329us/sample - loss: 3.5929 - acc: 0.2293\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 0s 332us/sample - loss: 3.5533 - acc: 0.2407\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 3.5078 - acc: 0.2447\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - 0s 324us/sample - loss: 3.4662 - acc: 0.2420\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - 0s 331us/sample - loss: 3.4188 - acc: 0.2467\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 0s 338us/sample - loss: 3.3692 - acc: 0.2613\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 3.3149 - acc: 0.2740\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - 0s 346us/sample - loss: 3.2542 - acc: 0.2787\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - 0s 338us/sample - loss: 3.1858 - acc: 0.2860\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 0s 336us/sample - loss: 3.1088 - acc: 0.2940\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - 0s 330us/sample - loss: 3.0228 - acc: 0.2980\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 2.9290 - acc: 0.3080\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - 0s 327us/sample - loss: 2.8273 - acc: 0.3213\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 0s 331us/sample - loss: 2.7176 - acc: 0.3360\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - 0s 340us/sample - loss: 2.6084 - acc: 0.3567\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - 0s 331us/sample - loss: 2.5019 - acc: 0.3940\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - 0s 339us/sample - loss: 2.3943 - acc: 0.4193\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 0s 341us/sample - loss: 2.2913 - acc: 0.4487\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 2.1872 - acc: 0.4813\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - 0s 329us/sample - loss: 2.0884 - acc: 0.5127\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 1.9915 - acc: 0.5487\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 1.8986 - acc: 0.5820\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - 0s 327us/sample - loss: 1.8115 - acc: 0.6100\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - 0s 319us/sample - loss: 1.7264 - acc: 0.6487\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - 0s 305us/sample - loss: 1.6452 - acc: 0.6720\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 0s 311us/sample - loss: 1.5676 - acc: 0.6967\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 1.4928 - acc: 0.7140\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - 0s 331us/sample - loss: 1.4209 - acc: 0.7420\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - 0s 348us/sample - loss: 1.3524 - acc: 0.7773\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 1.2871 - acc: 0.7960\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 1.2246 - acc: 0.8187\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 1.1665 - acc: 0.8280\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - 0s 322us/sample - loss: 1.1099 - acc: 0.8380\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 1.0571 - acc: 0.8533\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 1.0070 - acc: 0.8627\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 0.9608 - acc: 0.8720\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.9171 - acc: 0.8793\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 0s 334us/sample - loss: 0.8769 - acc: 0.8860\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - 0s 321us/sample - loss: 0.8375 - acc: 0.8887\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - 0s 330us/sample - loss: 0.8026 - acc: 0.8947\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.7696 - acc: 0.9000\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.7383 - acc: 0.9067\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - 0s 328us/sample - loss: 0.7096 - acc: 0.9080\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - 0s 322us/sample - loss: 0.6823 - acc: 0.9113\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - 0s 322us/sample - loss: 0.6570 - acc: 0.9153\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 0s 328us/sample - loss: 0.6338 - acc: 0.9160\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - 0s 322us/sample - loss: 0.6120 - acc: 0.9187\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - 0s 343us/sample - loss: 0.5917 - acc: 0.9220\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - 0s 329us/sample - loss: 0.5725 - acc: 0.9227\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 0s 345us/sample - loss: 0.5551 - acc: 0.9247\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - 0s 327us/sample - loss: 0.5385 - acc: 0.9260\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 0.5228 - acc: 0.9267\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - 0s 336us/sample - loss: 0.5084 - acc: 0.9280\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 0s 333us/sample - loss: 0.4949 - acc: 0.9280\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - 0s 325us/sample - loss: 0.4820 - acc: 0.9287\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 0.4700 - acc: 0.9293\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 0.4588 - acc: 0.9307\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 0s 333us/sample - loss: 0.4485 - acc: 0.9320\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 0.4382 - acc: 0.9313\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - 0s 321us/sample - loss: 0.4290 - acc: 0.9307\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - 0s 297us/sample - loss: 0.4197 - acc: 0.9320\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 0s 348us/sample - loss: 0.4113 - acc: 0.9333\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 0.4033 - acc: 0.9333\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 0.3957 - acc: 0.9340\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 0.3884 - acc: 0.9353\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.3815 - acc: 0.9353\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - 0s 310us/sample - loss: 0.3750 - acc: 0.9353\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - 0s 328us/sample - loss: 0.3686 - acc: 0.9360\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.3627 - acc: 0.9360\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.3569 - acc: 0.9360\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - 0s 364us/sample - loss: 0.3514 - acc: 0.9360\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 383us/sample - loss: 0.3461 - acc: 0.9360\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - 0s 394us/sample - loss: 0.3410 - acc: 0.9367\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 0s 405us/sample - loss: 0.3362 - acc: 0.9393\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - 0s 359us/sample - loss: 0.3316 - acc: 0.9387\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.3270 - acc: 0.9393\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - 0s 384us/sample - loss: 0.3226 - acc: 0.9393\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 0s 378us/sample - loss: 0.3185 - acc: 0.9387\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - 0s 393us/sample - loss: 0.3145 - acc: 0.9393\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - 0s 341us/sample - loss: 0.3105 - acc: 0.9393\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - 0s 319us/sample - loss: 0.3071 - acc: 0.9393\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 0.3032 - acc: 0.9393\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - 0s 322us/sample - loss: 0.2997 - acc: 0.9393\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - 0s 311us/sample - loss: 0.2962 - acc: 0.9400\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.2929 - acc: 0.9407\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 0s 321us/sample - loss: 0.2896 - acc: 0.9407\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - 0s 309us/sample - loss: 0.2866 - acc: 0.9407\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - 0s 306us/sample - loss: 0.2836 - acc: 0.9407\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - 0s 298us/sample - loss: 0.2806 - acc: 0.9407\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 0s 299us/sample - loss: 0.2777 - acc: 0.9407\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.2750 - acc: 0.9407\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.2723 - acc: 0.9400\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.2696 - acc: 0.9400\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.2671 - acc: 0.9407\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.2646 - acc: 0.9407\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - 0s 319us/sample - loss: 0.2626 - acc: 0.9393\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 0.2598 - acc: 0.9400\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.2575 - acc: 0.9393\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - 0s 319us/sample - loss: 0.2552 - acc: 0.9407\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - 0s 310us/sample - loss: 0.2530 - acc: 0.9400\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - 0s 329us/sample - loss: 0.2508 - acc: 0.9400\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.2491 - acc: 0.9407\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - 0s 319us/sample - loss: 0.2468 - acc: 0.9413\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.2449 - acc: 0.9407\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 0.2428 - acc: 0.9413\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.2409 - acc: 0.9413\n",
      "Epoch 117/200\n",
      "150/150 [==============================] - 0s 325us/sample - loss: 0.2391 - acc: 0.9420\n",
      "Epoch 118/200\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.2372 - acc: 0.9420\n",
      "Epoch 119/200\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.2355 - acc: 0.9420\n",
      "Epoch 120/200\n",
      "150/150 [==============================] - 0s 309us/sample - loss: 0.2337 - acc: 0.9407\n",
      "Epoch 121/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.2320 - acc: 0.9420\n",
      "Epoch 122/200\n",
      "150/150 [==============================] - 0s 324us/sample - loss: 0.2303 - acc: 0.9420\n",
      "Epoch 123/200\n",
      "150/150 [==============================] - 0s 324us/sample - loss: 0.2288 - acc: 0.9420\n",
      "Epoch 124/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.2274 - acc: 0.9413\n",
      "Epoch 125/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 0.2257 - acc: 0.9420\n",
      "Epoch 126/200\n",
      "150/150 [==============================] - 0s 322us/sample - loss: 0.2243 - acc: 0.9413\n",
      "Epoch 127/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 0.2226 - acc: 0.9407\n",
      "Epoch 128/200\n",
      "150/150 [==============================] - 0s 300us/sample - loss: 0.2211 - acc: 0.9420\n",
      "Epoch 129/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 0.2200 - acc: 0.9400\n",
      "Epoch 130/200\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 0.2185 - acc: 0.9413\n",
      "Epoch 131/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.2170 - acc: 0.9407\n",
      "Epoch 132/200\n",
      "150/150 [==============================] - 0s 321us/sample - loss: 0.2158 - acc: 0.9413\n",
      "Epoch 133/200\n",
      "150/150 [==============================] - 0s 324us/sample - loss: 0.2145 - acc: 0.9420\n",
      "Epoch 134/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.2131 - acc: 0.9433\n",
      "Epoch 135/200\n",
      "150/150 [==============================] - 0s 311us/sample - loss: 0.2119 - acc: 0.9420\n",
      "Epoch 136/200\n",
      "150/150 [==============================] - 0s 299us/sample - loss: 0.2107 - acc: 0.9427\n",
      "Epoch 137/200\n",
      "150/150 [==============================] - 0s 327us/sample - loss: 0.2094 - acc: 0.9413\n",
      "Epoch 138/200\n",
      "150/150 [==============================] - 0s 311us/sample - loss: 0.2082 - acc: 0.9413\n",
      "Epoch 139/200\n",
      "150/150 [==============================] - 0s 307us/sample - loss: 0.2071 - acc: 0.9407\n",
      "Epoch 140/200\n",
      "150/150 [==============================] - 0s 301us/sample - loss: 0.2060 - acc: 0.9420\n",
      "Epoch 141/200\n",
      "150/150 [==============================] - 0s 301us/sample - loss: 0.2049 - acc: 0.9413\n",
      "Epoch 142/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.2037 - acc: 0.9420\n",
      "Epoch 143/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.2027 - acc: 0.9420\n",
      "Epoch 144/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.2016 - acc: 0.9420\n",
      "Epoch 145/200\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 0.2007 - acc: 0.9420\n",
      "Epoch 146/200\n",
      "150/150 [==============================] - 0s 310us/sample - loss: 0.1995 - acc: 0.9427\n",
      "Epoch 147/200\n",
      "150/150 [==============================] - 0s 330us/sample - loss: 0.1984 - acc: 0.9427\n",
      "Epoch 148/200\n",
      "150/150 [==============================] - 0s 325us/sample - loss: 0.1975 - acc: 0.9427\n",
      "Epoch 149/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.1968 - acc: 0.9413\n",
      "Epoch 150/200\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 0.1956 - acc: 0.9420\n",
      "Epoch 151/200\n",
      "150/150 [==============================] - 0s 307us/sample - loss: 0.1946 - acc: 0.9427\n",
      "Epoch 152/200\n",
      "150/150 [==============================] - 0s 307us/sample - loss: 0.1939 - acc: 0.9420\n",
      "Epoch 153/200\n",
      "150/150 [==============================] - 0s 317us/sample - loss: 0.1931 - acc: 0.9427\n",
      "Epoch 154/200\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.1921 - acc: 0.9413\n",
      "Epoch 155/200\n",
      "150/150 [==============================] - 0s 309us/sample - loss: 0.1911 - acc: 0.9400\n",
      "Epoch 156/200\n",
      "150/150 [==============================] - 0s 287us/sample - loss: 0.1902 - acc: 0.9420\n",
      "Epoch 157/200\n",
      "150/150 [==============================] - 0s 289us/sample - loss: 0.1895 - acc: 0.9427\n",
      "Epoch 158/200\n",
      "150/150 [==============================] - 0s 308us/sample - loss: 0.1887 - acc: 0.9420\n",
      "Epoch 159/200\n",
      "150/150 [==============================] - 0s 303us/sample - loss: 0.1880 - acc: 0.9420\n",
      "Epoch 160/200\n",
      "150/150 [==============================] - 0s 297us/sample - loss: 0.1874 - acc: 0.9413\n",
      "Epoch 161/200\n",
      "150/150 [==============================] - 0s 311us/sample - loss: 0.1862 - acc: 0.9427\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 310us/sample - loss: 0.1860 - acc: 0.9420\n",
      "Epoch 163/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.1848 - acc: 0.9427\n",
      "Epoch 164/200\n",
      "150/150 [==============================] - 0s 319us/sample - loss: 0.1844 - acc: 0.9420\n",
      "Epoch 165/200\n",
      "150/150 [==============================] - 0s 302us/sample - loss: 0.1834 - acc: 0.9420\n",
      "Epoch 166/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.1829 - acc: 0.9413\n",
      "Epoch 167/200\n",
      "150/150 [==============================] - 0s 300us/sample - loss: 0.1820 - acc: 0.9413\n",
      "Epoch 168/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.1813 - acc: 0.9413\n",
      "Epoch 169/200\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.1807 - acc: 0.9407\n",
      "Epoch 170/200\n",
      "150/150 [==============================] - 0s 308us/sample - loss: 0.1800 - acc: 0.9420\n",
      "Epoch 171/200\n",
      "150/150 [==============================] - 0s 309us/sample - loss: 0.1794 - acc: 0.9413\n",
      "Epoch 172/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.1788 - acc: 0.9427\n",
      "Epoch 173/200\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.1781 - acc: 0.9427\n",
      "Epoch 174/200\n",
      "150/150 [==============================] - 0s 301us/sample - loss: 0.1773 - acc: 0.9427\n",
      "Epoch 175/200\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 0.1768 - acc: 0.9407\n",
      "Epoch 176/200\n",
      "150/150 [==============================] - 0s 303us/sample - loss: 0.1763 - acc: 0.9420\n",
      "Epoch 177/200\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 0.1756 - acc: 0.9420\n",
      "Epoch 178/200\n",
      "150/150 [==============================] - 0s 306us/sample - loss: 0.1750 - acc: 0.9433\n",
      "Epoch 179/200\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.1746 - acc: 0.9407\n",
      "Epoch 180/200\n",
      "150/150 [==============================] - 0s 309us/sample - loss: 0.1743 - acc: 0.9413\n",
      "Epoch 181/200\n",
      "150/150 [==============================] - 0s 312us/sample - loss: 0.1734 - acc: 0.9420\n",
      "Epoch 182/200\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.1731 - acc: 0.9420\n",
      "Epoch 183/200\n",
      "150/150 [==============================] - 0s 298us/sample - loss: 0.1723 - acc: 0.9413\n",
      "Epoch 184/200\n",
      "150/150 [==============================] - 0s 295us/sample - loss: 0.1720 - acc: 0.9420\n",
      "Epoch 185/200\n",
      "150/150 [==============================] - 0s 305us/sample - loss: 0.1715 - acc: 0.9427\n",
      "Epoch 186/200\n",
      "150/150 [==============================] - 0s 297us/sample - loss: 0.1711 - acc: 0.9420\n",
      "Epoch 187/200\n",
      "150/150 [==============================] - 0s 284us/sample - loss: 0.1703 - acc: 0.9413\n",
      "Epoch 188/200\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.1698 - acc: 0.9420\n",
      "Epoch 189/200\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.1699 - acc: 0.9413\n",
      "Epoch 190/200\n",
      "150/150 [==============================] - 0s 311us/sample - loss: 0.1689 - acc: 0.9400\n",
      "Epoch 191/200\n",
      "150/150 [==============================] - 0s 297us/sample - loss: 0.1685 - acc: 0.9413\n",
      "Epoch 192/200\n",
      "150/150 [==============================] - 0s 308us/sample - loss: 0.1680 - acc: 0.9413\n",
      "Epoch 193/200\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.1675 - acc: 0.9407\n",
      "Epoch 194/200\n",
      "150/150 [==============================] - 0s 320us/sample - loss: 0.1670 - acc: 0.9420\n",
      "Epoch 195/200\n",
      "150/150 [==============================] - 0s 326us/sample - loss: 0.1670 - acc: 0.9387\n",
      "Epoch 196/200\n",
      "150/150 [==============================] - 0s 324us/sample - loss: 0.1662 - acc: 0.9400\n",
      "Epoch 197/200\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.1658 - acc: 0.9420\n",
      "Epoch 198/200\n",
      "150/150 [==============================] - 0s 300us/sample - loss: 0.1656 - acc: 0.9400\n",
      "Epoch 199/200\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.1653 - acc: 0.9400\n",
      "Epoch 200/200\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 0.1648 - acc: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1423e2a20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data, y_data, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1532,
     "status": "ok",
     "timestamp": 1578898194450,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "WPN1UDEDoO1s",
    "outputId": "a0ca5234-5754-4379-d916-ba267abc3299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 10, 64)\n",
      "(150, 10)\n",
      "\n",
      "린 부리 파랑새\n",
      "사랑이라는 빛 하나 싣다\n",
      "\n",
      "바람 지나는 밤낮\n",
      "나의 온기속에 그대 심장을\n",
      "그대 온기 속에 나의 심장을\n",
      "\n",
      "미소도 눈물도 두 심장\n",
      "하나의 맥박되어\n",
      "\n",
      "덤불 어지러운 미물의 제자리걸음\n",
      "빛으로 이끌어내며\n",
      "사철바람 타고 날개치는\n",
      "\n",
      "고운 부리 파랑새\n",
      "사랑이라는 빛 하나 싣고 간다\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_data)    # 본 예제는 training에 사용한 데이터를 예측에 사용했기 때문에 100% 정확한 값을 출력함(전체적인 로직만 참고)\n",
    "print(pred.shape)\n",
    "\n",
    "pred = np.argmax(pred, axis=2)\n",
    "print(pred.shape)\n",
    "\n",
    "for i, str in enumerate(pred):\n",
    "    if i == 0:\n",
    "        print(\"\".join([char_set[c] for c in str]), end='')\n",
    "    else:\n",
    "        print(char_set[str[-1]], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzXMsb_r653C"
   },
   "source": [
    "# Embedding (영화 리뷰 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5731,
     "status": "ok",
     "timestamp": 1578903322940,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "wcWZtvQWo_nw",
    "outputId": "d53c9892-9e6d-4ee7-a7b8-955001ad6f9f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6321,
     "status": "ok",
     "timestamp": 1578903330353,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "oU1nxCg_6_fo",
    "outputId": "9751aa35-948a-4734-b88a-deb8b16073b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1201,
     "status": "ok",
     "timestamp": 1578903332722,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "XDoyT4gO7Uxp",
    "outputId": "6ddc9b1f-f359-4e33-aa54-d47897012de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n",
      "11\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(max([len(text) for text in x_train]))\n",
    "print(min([len(text) for text in x_train]))\n",
    "print(max([max(text) for text in x_train]))   # 원핫벡터의 차원 수 (데이터 로드 시 단어의 수를 10,000개로 제한 했음))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7114,
     "status": "ok",
     "timestamp": 1578903348244,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "3nUiRfeq7jf_",
    "outputId": "6587ae29-bfe6-4db2-c18f-b0d289d50a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000, 64)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=64)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1578903858910,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "5nP_GfDg9HhC",
    "outputId": "185af186-5c07-405b-baf4-3dcedf3205b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alex/venvs/tensorflow-1x/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.layers.Input(shape=(64, ))\n",
    "\n",
    "net = tf.keras.layers.Embedding(10000, 30)(X)\n",
    "# (25000, 64, 30)\n",
    "\n",
    "cell = tf.keras.layers.LSTMCell(50)\n",
    "net = tf.keras.layers.RNN(cell)(net)\n",
    "net = tf.keras.layers.Dense(1)(net)\n",
    "Y = tf.keras.layers.Activation('sigmoid')(net)\n",
    "\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1578903861846,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "-6UN0MzQ_FHr",
    "outputId": "f729be50-1888-45aa-d676-70b3c26f3934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 64, 30)            300000    \n",
      "_________________________________________________________________\n",
      "rnn_5 (RNN)                  (None, 50)                16200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 316,251\n",
      "Trainable params: 316,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0VxKzvp_KZX"
   },
   "outputs": [],
   "source": [
    "# rnn parameter(LSTM 이기 때문에 4배) : ((30 + 50) * 50 + 50) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542292,
     "status": "ok",
     "timestamp": 1578904407742,
     "user": {
      "displayName": "이성식",
      "photoUrl": "",
      "userId": "14835492147461659891"
     },
     "user_tz": -540
    },
    "id": "94lHBDQx_pig",
    "outputId": "8ca1931c-7df9-4cc3-de1f-50fc2a3dd461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.4448 - acc: 0.7883\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.3107 - acc: 0.8691\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.2578 - acc: 0.8941\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.2040 - acc: 0.9198\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.1545 - acc: 0.9391\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.1152 - acc: 0.9562\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.0959 - acc: 0.9645\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 37s 1ms/sample - loss: 0.0762 - acc: 0.9731\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 34s 1ms/sample - loss: 0.0663 - acc: 0.9766\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.0499 - acc: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142c9eb38>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfyORf1x_3ZX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpu8C8XP4giLT0zstw98Bj",
   "collapsed_sections": [
    "PFF4IRLTYa_s",
    "buzYEhw3gkH_"
   ],
   "name": "1일차RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Keras-AutoEncoder\" data-toc-modified-id=\"Keras-AutoEncoder-1\">Keras AutoEncoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#MLP---PLC\" data-toc-modified-id=\"MLP---PLC-1.1\">MLP - PLC</a></span></li><li><span><a href=\"#Autoencoder-on-Iris-Dataset\" data-toc-modified-id=\"Autoencoder-on-Iris-Dataset-1.2\">Autoencoder on Iris Dataset</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - PLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_classes = 3\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plc=pd.read_csv(\"plc2.csv\")\n",
    "plc.drop([\"Date\", \"Time\"], axis=1, inplace=True)\n",
    "\n",
    "# Shuffling\n",
    "plc=plc.sample(frac=1).reset_index(drop=True)\n",
    "plc_train=plc.iloc[0:100,:]\n",
    "plc_test=plc.iloc[100:150,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source, target\n",
    "x_train=plc_train.iloc[:,0:6].values\n",
    "x_test=plc_test.iloc[:,0:6].values\n",
    "y_train=plc_train.iloc[:,6:]\n",
    "y_test=plc_test.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder={k:v for v,k in enumerate(y_train.drop_duplicates())}\n",
    "# encoder\n",
    "#sets=np.unique(plc.iloc[:,6:].values)\n",
    "sets=plc.iloc[:,6:].drop_duplicates()[\"state\"].tolist()\n",
    "sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder={k:v for v,k in enumerate(sets)}\n",
    "\n",
    "y_train=[ encoder[i] for i in y_train[\"state\"].tolist() ]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "y_test=[ encoder[i] for i in y_test[\"state\"].tolist() ]\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 shape 을 확인해 봅니다.\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_shape=(6,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder on Iris Dataset\n",
    "\n",
    "* Source : https://www.kaggle.com/shivam1600/autoencoder-on-iris-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "display(data.head())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[['Sepal.Length', 'Sepal.Width',\n",
    "                                                          'Petal.Length', 'Petal.Width']],\n",
    "                                                    data['Species'],test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim1 = 6\n",
    "encoding_dim2 = 4\n",
    "encoding_dim3 = 2\n",
    "input_dim = 4\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim1)(input_img)\n",
    "encoded = Dense(encoding_dim2)(encoded)\n",
    "encoded = Dense(encoding_dim3)(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(encoding_dim2)(encoded)\n",
    "decoded = Dense(encoding_dim1)(decoded)\n",
    "decoded = Dense(input_dim)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "#encoder = decoder_layer = autoencoder.layers[3]\n",
    "\n",
    "# create a placeholder for an encoded (2-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim3,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "\n",
    "decoder_layer = autoencoder.layers[-3](encoded_input)\n",
    "decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer)\n",
    "opt=RMSprop(lr=0.001)\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=opt)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=333,\n",
    "                batch_size=123,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "               callbacks=[])\n",
    "\n",
    "# encode and decode some data points\n",
    "# note that we take them from the *test* set\n",
    "encoded_datapoints = encoder.predict(x_test)\n",
    "decoded_datapoints = decoder.predict(encoded_datapoints)\n",
    "\n",
    "print('Original Datapoints :')\n",
    "print(x_test)\n",
    "print('Reconstructed Datapoints :')\n",
    "print(decoded_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Encoded Features\n",
    "encoded_dataset = encoder.predict(x_test[['Sepal.Length', 'Sepal.Width',\n",
    "                                        'Petal.Length', 'Petal.Width']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Dataset\n",
    "plt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoded Dataset(reconstruncted)\n",
    "decoded_dataset=decoder.predict(encoded_dataset)\n",
    "plt.scatter(decoded_dataset[:,2], decoded_dataset[:,3], c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orignal Data\n",
    "plt.scatter(x_test['Petal.Length'], x_test['Petal.Width'],c=y_test.astype('category').cat.codes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
